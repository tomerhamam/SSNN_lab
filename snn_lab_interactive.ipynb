{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Supervised Neural Networks: An Interactive Lab\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this lab, you will:\n",
    "- Understand the core principles of self-supervised learning (SSL)\n",
    "- Implement pretext tasks for vision and time-series data\n",
    "- Evaluate representation quality through transfer learning\n",
    "- Compare generative vs. discriminative SSL approaches\n",
    "- Build intuition about when and why SSL works\n",
    "\n",
    "## üìö Prerequisites\n",
    "- Basic understanding of neural networks and backpropagation\n",
    "- Familiarity with NumPy and Python\n",
    "- Linear algebra fundamentals (matrix multiplication, derivatives)\n",
    "\n",
    "## üîó Recommended Reading\n",
    "Before starting, consider reviewing:\n",
    "- [A Survey on Self-supervised Learning](https://arxiv.org/abs/2301.05712)\n",
    "- [Representation Learning: A Review and New Perspectives](https://arxiv.org/abs/1206.5538)\n",
    "- [Self-supervised Visual Feature Learning with Deep Neural Networks](https://arxiv.org/abs/1712.05577)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Introduction to Self-Supervised Learning\n",
    "\n",
    "Self-supervised learning (SSL) is a paradigm where models learn representations from unlabeled data by solving **pretext tasks**. The model generates its own supervision signal from the data structure itself.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Two Main Families of SSL:**\n",
    "1. **Generative/Predictive Methods**: Reconstruct or predict part of the input\n",
    "   - Examples: Autoencoders, masked language modeling (BERT), image inpainting\n",
    "   - Learns by minimizing reconstruction error\n",
    "\n",
    "2. **Discriminative/Contrastive Methods**: Learn to distinguish between different views\n",
    "   - Examples: SimCLR, MoCo, SwAV\n",
    "   - Learns by pulling positive pairs together, pushing negatives apart\n",
    "\n",
    "### ü§î Critical Thinking Question 1\n",
    "**Why might SSL be particularly valuable in domains like medical imaging or astronomy?**\n",
    "\n",
    "*Think about data availability, labeling costs, and domain expertise requirements.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Multiple Choice Question 1\n",
    "**Which of the following is NOT a typical pretext task in self-supervised learning?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple choice question implementation\n",
    "class MultipleChoiceQuestion:\n",
    "    def __init__(self, question, options, correct_answer, explanation):\n",
    "        self.question = question\n",
    "        self.options = options\n",
    "        self.correct_answer = correct_answer\n",
    "        self.explanation = explanation\n",
    "    \n",
    "    def display(self):\n",
    "        print(self.question)\n",
    "        for i, option in enumerate(self.options, 1):\n",
    "            print(f\"{i}. {option}\")\n",
    "    \n",
    "    def check_answer(self, answer):\n",
    "        if answer == self.correct_answer:\n",
    "            print(\"‚úÖ Correct!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Incorrect. The correct answer is {self.correct_answer}.\")\n",
    "        print(f\"Explanation: {self.explanation}\")\n",
    "\n",
    "mcq1 = MultipleChoiceQuestion(\n",
    "    \"Which of the following is NOT a typical pretext task in self-supervised learning?\",\n",
    "    [\n",
    "        \"Predicting image rotations\",\n",
    "        \"Classifying images into predefined categories\",\n",
    "        \"Reconstructing masked patches\",\n",
    "        \"Predicting next words in a sentence\"\n",
    "    ],\n",
    "    2,\n",
    "    \"Classification into predefined categories requires labeled data, making it supervised learning, not self-supervised.\"\n",
    ")\n",
    "\n",
    "mcq1.display()\n",
    "# To check your answer, uncomment and run:\n",
    "# mcq1.check_answer(YOUR_ANSWER_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Computer Vision - Rotation Prediction\n",
    "\n",
    "We'll implement a rotation prediction pretext task using the digits dataset. The model learns to predict how much an image has been rotated, developing useful features in the process.\n",
    "\n",
    "### Step 1: Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Pixel value range: [{X.min()}, {X.max()}]\")\n",
    "\n",
    "# Visualize sample digits\n",
    "fig, axes = plt.subplots(2, 10, figsize=(12, 3))\n",
    "for i in range(20):\n",
    "    ax = axes[i // 10, i % 10]\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {digits.target[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample Digits from Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "X = X.astype('float32') / 16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Exercise 1: Implement Data Augmentation (Easy)\n",
    "Complete the function below to create rotated versions of images. This is your first pretext task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotation_dataset(X: np.ndarray, \n",
    "                          rotations: Tuple[int, ...] = (0, 90, 180, 270)\n",
    "                          ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create a dataset of rotated images for the pretext task.\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    Hint: Use np.rot90() with k parameter for 90-degree rotations\n",
    "    \"\"\"\n",
    "    images = X.reshape(-1, 8, 8)\n",
    "    rot_images = []\n",
    "    rot_labels = []\n",
    "    \n",
    "    for idx, angle in enumerate(rotations):\n",
    "        # TODO: Calculate how many 90-degree rotations needed\n",
    "        k = ___  # FILL THIS\n",
    "        \n",
    "        for img in images:\n",
    "            # TODO: Rotate the image and add to lists\n",
    "            rotated = ___  # FILL THIS\n",
    "            rot_images.append(___) # FILL THIS (hint: flatten the rotated image)\n",
    "            rot_labels.append(___) # FILL THIS (hint: use idx)\n",
    "    \n",
    "    return np.array(rot_images, dtype=np.float32), np.array(rot_labels, dtype=np.int64)\n",
    "\n",
    "# Test your implementation\n",
    "# rot_X, rot_y = create_rotation_dataset(X[:10])  # Test with first 10 images\n",
    "# print(f\"Rotated dataset shape: {rot_X.shape}\")\n",
    "# print(f\"Labels shape: {rot_y.shape}\")\n",
    "# print(f\"Unique labels: {np.unique(rot_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution for Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (hidden by default - uncomment to reveal)\n",
    "\"\"\"\n",
    "def create_rotation_dataset(X: np.ndarray, \n",
    "                          rotations: Tuple[int, ...] = (0, 90, 180, 270)\n",
    "                          ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    images = X.reshape(-1, 8, 8)\n",
    "    rot_images = []\n",
    "    rot_labels = []\n",
    "    \n",
    "    for idx, angle in enumerate(rotations):\n",
    "        k = (angle // 90) % 4\n",
    "        \n",
    "        for img in images:\n",
    "            rotated = np.rot90(img, k=k)\n",
    "            rot_images.append(rotated.flatten())\n",
    "            rot_labels.append(idx)\n",
    "    \n",
    "    return np.array(rot_images, dtype=np.float32), np.array(rot_labels, dtype=np.int64)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the Neural Network\n",
    "\n",
    "Now we'll implement a simple 2-layer neural network from scratch. This helps you understand the fundamentals of SSL without framework abstractions.\n",
    "\n",
    "### üíª Exercise 2: Complete the Forward Pass (Medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TwoLayerNet:\n",
    "    \"\"\"A simple two-layer neural network for rotation prediction.\"\"\"\n",
    "    input_dim: int\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    learning_rate: float = 0.5\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Initialize weights\n",
    "        rng = np.random.default_rng(0)\n",
    "        self.W1 = rng.standard_normal((self.input_dim, self.hidden_dim)) * 0.01\n",
    "        self.b1 = np.zeros(self.hidden_dim)\n",
    "        self.W2 = rng.standard_normal((self.hidden_dim, self.output_dim)) * 0.01\n",
    "        self.b2 = np.zeros(self.output_dim)\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> Tuple[np.ndarray, Tuple]:\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        TODO: Complete the forward pass\n",
    "        Steps:\n",
    "        1. Linear transformation: z1 = X @ W1 + b1\n",
    "        2. Activation: a1 = tanh(z1)\n",
    "        3. Linear transformation: z2 = a1 @ W2 + b2\n",
    "        4. Softmax: convert z2 to probabilities\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "        z1 = ___  # FILL: Linear transformation\n",
    "        a1 = ___  # FILL: Apply tanh activation\n",
    "        \n",
    "        # Layer 2\n",
    "        z2 = ___  # FILL: Linear transformation\n",
    "        \n",
    "        # Softmax (stable version)\n",
    "        exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
    "        probs = ___  # FILL: Normalize exp_scores to get probabilities\n",
    "        \n",
    "        cache = (X, z1, a1, z2, probs)\n",
    "        return probs, cache\n",
    "    \n",
    "    def backward(self, cache, y_true):\n",
    "        \"\"\"Backward pass (provided for you).\"\"\"\n",
    "        X, z1, a1, z2, probs = cache\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Convert labels to one-hot\n",
    "        one_hot = np.zeros_like(probs)\n",
    "        one_hot[np.arange(n_samples), y_true] = 1\n",
    "        \n",
    "        # Gradients\n",
    "        dz2 = (probs - one_hot) / n_samples\n",
    "        dW2 = a1.T.dot(dz2)\n",
    "        db2 = dz2.sum(axis=0)\n",
    "        \n",
    "        da1 = dz2.dot(self.W2.T)\n",
    "        dz1 = da1 * (1.0 - np.tanh(z1)**2)\n",
    "        dW1 = X.T.dot(dz1)\n",
    "        db1 = dz1.sum(axis=0)\n",
    "        \n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    def update_params(self, dW1, db1, dW2, db2):\n",
    "        \"\"\"Update parameters using gradient descent.\"\"\"\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "    \n",
    "    def train(self, X, y, epochs=20, batch_size=128, verbose=False):\n",
    "        \"\"\"Training loop.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle data\n",
    "            idx = np.random.permutation(n_samples)\n",
    "            X_shuf, y_shuf = X[idx], y[idx]\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            n_batches = 0\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                X_batch = X_shuf[start:end]\n",
    "                y_batch = y_shuf[start:end]\n",
    "                \n",
    "                # Forward and backward\n",
    "                probs, cache = self.forward(X_batch)\n",
    "                grads = self.backward(cache, y_batch)\n",
    "                self.update_params(*grads)\n",
    "                \n",
    "                # Calculate loss\n",
    "                batch_loss = -np.log(probs[np.arange(len(y_batch)), y_batch] + 1e-8).mean()\n",
    "                epoch_loss += batch_loss\n",
    "                n_batches += 1\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        probs, _ = self.forward(X)\n",
    "        return probs.argmax(axis=1)\n",
    "    \n",
    "    def hidden_representation(self, X):\n",
    "        \"\"\"Extract hidden layer features.\"\"\"\n",
    "        z1 = X.dot(self.W1) + self.b1\n",
    "        return np.tanh(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Critical Thinking Question 2\n",
    "**Why do we use tanh activation instead of ReLU for this simple network?**\n",
    "\n",
    "*Consider: gradient flow, bounded outputs, and the historical context of when tanh was popular.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the Rotation Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rotation dataset (using the solution)\n",
    "def create_rotation_dataset_solution(X: np.ndarray, \n",
    "                          rotations: Tuple[int, ...] = (0, 90, 180, 270)\n",
    "                          ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    images = X.reshape(-1, 8, 8)\n",
    "    rot_images = []\n",
    "    rot_labels = []\n",
    "    \n",
    "    for idx, angle in enumerate(rotations):\n",
    "        k = (angle // 90) % 4\n",
    "        for img in images:\n",
    "            rotated = np.rot90(img, k=k)\n",
    "            rot_images.append(rotated.flatten())\n",
    "            rot_labels.append(idx)\n",
    "    \n",
    "    return np.array(rot_images, dtype=np.float32), np.array(rot_labels, dtype=np.int64)\n",
    "\n",
    "# Create rotated dataset\n",
    "rot_X, rot_y = create_rotation_dataset_solution(X)\n",
    "print(f\"Rotation dataset size: {rot_X.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    rot_X, rot_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the network (with solution for forward pass)\n",
    "class TwoLayerNetComplete(TwoLayerNet):\n",
    "    def forward(self, X: np.ndarray) -> Tuple[np.ndarray, Tuple]:\n",
    "        z1 = X.dot(self.W1) + self.b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(self.W2) + self.b2\n",
    "        exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
    "        probs = exp_scores / exp_scores.sum(axis=1, keepdims=True)\n",
    "        cache = (X, z1, a1, z2, probs)\n",
    "        return probs, cache\n",
    "\n",
    "# Train\n",
    "net = TwoLayerNetComplete(input_dim=64, hidden_dim=32, output_dim=4, learning_rate=0.3)\n",
    "losses = net.train(X_train, y_train, epochs=15, batch_size=256, verbose=True)\n",
    "\n",
    "# Evaluate\n",
    "val_preds = net.predict(X_val)\n",
    "val_acc = (val_preds == y_val).mean()\n",
    "print(f\"\\nRotation classification accuracy: {val_acc:.3f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss for Rotation Prediction')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Exercise 3: Analyze Learned Features (Medium-Hard)\n",
    "Implement a function to visualize what features the network has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_learned_features(net, X_sample, n_features=8):\n",
    "    \"\"\"\n",
    "    Visualize the activation patterns of hidden units.\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    1. Get hidden representations for sample images\n",
    "    2. Find images that maximally activate each hidden unit\n",
    "    3. Visualize these images\n",
    "    \"\"\"\n",
    "    # Get hidden representations\n",
    "    hidden = ___  # FILL: Use net.hidden_representation()\n",
    "    \n",
    "    # TODO: For each of the first n_features hidden units,\n",
    "    # find the image that activates it most strongly\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_features//2, figsize=(12, 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(n_features, hidden.shape[1])):\n",
    "        # TODO: Find index of maximum activation for hidden unit i\n",
    "        max_idx = ___  # FILL: np.argmax for column i\n",
    "        \n",
    "        # Reshape and display\n",
    "        img = X_sample[max_idx].reshape(8, 8)\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"Unit {i}\\nAct: {hidden[max_idx, i]:.2f}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Images that Maximally Activate Hidden Units\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test your implementation\n",
    "# visualize_learned_features(net, X[:100], n_features=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Transfer Learning for Digit Classification\n",
    "\n",
    "Now we'll use the features learned from rotation prediction for the downstream task of digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using the pretrained network\n",
    "features = net.hidden_representation(X)\n",
    "\n",
    "# Split for downstream task\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
    "    features, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Train classifiers\n",
    "clf_feat = LogisticRegression(max_iter=200, multi_class='auto', solver='lbfgs')\n",
    "clf_feat.fit(X_train_d, y_train_d)\n",
    "feat_acc = clf_feat.score(X_test_d, y_test_d)\n",
    "\n",
    "clf_base = LogisticRegression(max_iter=200, multi_class='auto', solver='lbfgs')\n",
    "clf_base.fit(X_train_raw, y_train_raw)\n",
    "base_acc = clf_base.score(X_test_raw, y_test_raw)\n",
    "\n",
    "print(f\"Digit classification using SSL features: {feat_acc:.3f}\")\n",
    "print(f\"Baseline classification on raw pixels: {base_acc:.3f}\")\n",
    "print(f\"Improvement: {(feat_acc - base_acc)*100:.1f}%\")\n",
    "\n",
    "# Visualize confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# SSL features confusion matrix\n",
    "y_pred_feat = clf_feat.predict(X_test_d)\n",
    "cm_feat = confusion_matrix(y_test_d, y_pred_feat)\n",
    "sns.heatmap(cm_feat, annot=True, fmt='d', ax=ax1, cmap='Blues')\n",
    "ax1.set_title(f'SSL Features (Acc: {feat_acc:.3f})')\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('True')\n",
    "\n",
    "# Baseline confusion matrix\n",
    "y_pred_base = clf_base.predict(X_test_raw)\n",
    "cm_base = confusion_matrix(y_test_raw, y_pred_base)\n",
    "sns.heatmap(cm_base, annot=True, fmt='d', ax=ax2, cmap='Blues')\n",
    "ax2.set_title(f'Raw Pixels (Acc: {base_acc:.3f})')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Multiple Choice Question 2\n",
    "**Why might SSL features sometimes underperform raw pixels on small, simple datasets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq2 = MultipleChoiceQuestion(\n",
    "    \"Why might SSL features sometimes underperform raw pixels on small, simple datasets?\",\n",
    "    [\n",
    "        \"The pretext task is too difficult\",\n",
    "        \"Information bottleneck: features may lose task-specific details\",\n",
    "        \"SSL always performs worse than supervised learning\",\n",
    "        \"The network architecture is too complex\"\n",
    "    ],\n",
    "    2,\n",
    "    \"SSL creates a bottleneck that captures general features but may lose fine-grained details important for simple tasks. SSL shines with limited labels or complex data.\"\n",
    ")\n",
    "\n",
    "mcq2.display()\n",
    "# mcq2.check_answer(YOUR_ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Time Series - Autoencoder\n",
    "\n",
    "Now we'll explore generative SSL using autoencoders on synthetic time series data.\n",
    "\n",
    "### Step 1: Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_sequences(n_samples=1000, length=50, freq0=1.0, freq1=3.0, noise_std=0.1):\n",
    "    \"\"\"Generate sine sequences with two different frequencies.\"\"\"\n",
    "    t = np.linspace(0, 2 * np.pi, length)\n",
    "    half = n_samples // 2\n",
    "    \n",
    "    # Class 0: low frequency\n",
    "    seq0 = np.sin(freq0 * t)[None, :] * np.ones((half, 1))\n",
    "    # Class 1: high frequency\n",
    "    seq1 = np.sin(freq1 * t)[None, :] * np.ones((n_samples - half, 1))\n",
    "    \n",
    "    X = np.concatenate([seq0, seq1], axis=0)\n",
    "    X += np.random.normal(scale=noise_std, size=X.shape)\n",
    "    y = np.concatenate([np.zeros(half, dtype=int), np.ones(n_samples - half, dtype=int)])\n",
    "    \n",
    "    return X.astype(np.float32), y\n",
    "\n",
    "# Generate data\n",
    "X_ts, y_ts = generate_sine_sequences()\n",
    "\n",
    "# Visualize examples\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(3):\n",
    "    plt.plot(X_ts[i], alpha=0.7, label=f\"Sample {i+1}\")\n",
    "plt.title(\"Class 0: Low Frequency\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(3):\n",
    "    plt.plot(X_ts[-(i+1)], alpha=0.7, label=f\"Sample {i+1}\")\n",
    "plt.title(\"Class 1: High Frequency\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Exercise 4: Implement Autoencoder Training (Hard)\n",
    "Complete the autoencoder implementation, focusing on the reconstruction loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Autoencoder:\n",
    "    \"\"\"Simple autoencoder for time series.\"\"\"\n",
    "    input_dim: int\n",
    "    hidden_dim: int\n",
    "    learning_rate: float = 0.1\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        rng = np.random.default_rng(1)\n",
    "        self.W_enc = rng.standard_normal((self.input_dim, self.hidden_dim)) * 0.05\n",
    "        self.b_enc = np.zeros(self.hidden_dim)\n",
    "        self.W_dec = rng.standard_normal((self.hidden_dim, self.input_dim)) * 0.05\n",
    "        self.b_dec = np.zeros(self.input_dim)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: encode then decode.\"\"\"\n",
    "        # Encode\n",
    "        z = X.dot(self.W_enc) + self.b_enc\n",
    "        h = np.tanh(z)\n",
    "        \n",
    "        # Decode\n",
    "        recon = h.dot(self.W_dec) + self.b_dec\n",
    "        return h, recon\n",
    "    \n",
    "    def compute_loss(self, X, recon):\n",
    "        \"\"\"\n",
    "        TODO: Implement mean squared error loss\n",
    "        \"\"\"\n",
    "        # FILL: Compute MSE between X and recon\n",
    "        loss = ___\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, h, recon):\n",
    "        \"\"\"\n",
    "        TODO: Complete the backward pass\n",
    "        Hint: Start from dL/d_recon = (recon - X) / n_samples\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Gradient of loss w.r.t reconstruction\n",
    "        d_recon = ___  # FILL: (recon - X) / n_samples\n",
    "        \n",
    "        # Decoder gradients\n",
    "        dW_dec = ___  # FILL: h.T @ d_recon\n",
    "        db_dec = ___  # FILL: sum over samples\n",
    "        \n",
    "        # Propagate to encoder\n",
    "        dh = ___  # FILL: d_recon @ W_dec.T\n",
    "        dz = dh * (1.0 - h**2)  # tanh derivative\n",
    "        \n",
    "        # Encoder gradients\n",
    "        dW_enc = ___  # FILL: X.T @ dz\n",
    "        db_enc = ___  # FILL: sum over samples\n",
    "        \n",
    "        return dW_enc, db_enc, dW_dec, db_dec\n",
    "    \n",
    "    def update_params(self, dW_enc, db_enc, dW_dec, db_dec):\n",
    "        self.W_enc -= self.learning_rate * dW_enc\n",
    "        self.b_enc -= self.learning_rate * db_enc\n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.b_dec -= self.learning_rate * db_dec\n",
    "    \n",
    "    def train(self, X, epochs=30, batch_size=64, verbose=False):\n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.permutation(n_samples)\n",
    "            X_shuf = X[idx]\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            n_batches = 0\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                X_batch = X_shuf[start:end]\n",
    "                \n",
    "                h, recon = self.forward(X_batch)\n",
    "                loss = self.compute_loss(X_batch, recon)\n",
    "                grads = self.backward(X_batch, h, recon)\n",
    "                self.update_params(*grads)\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                n_batches += 1\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def encode(self, X):\n",
    "        z = X.dot(self.W_enc) + self.b_enc\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        h = self.encode(X)\n",
    "        return h.dot(self.W_dec) + self.b_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete autoencoder implementation (solution)\n",
    "class AutoencoderComplete(Autoencoder):\n",
    "    def compute_loss(self, X, recon):\n",
    "        return np.mean((X - recon)**2)\n",
    "    \n",
    "    def backward(self, X, h, recon):\n",
    "        n_samples = X.shape[0]\n",
    "        d_recon = (recon - X) / n_samples\n",
    "        dW_dec = h.T.dot(d_recon)\n",
    "        db_dec = d_recon.sum(axis=0)\n",
    "        dh = d_recon.dot(self.W_dec.T)\n",
    "        dz = dh * (1.0 - h**2)\n",
    "        dW_enc = X.T.dot(dz)\n",
    "        db_enc = dz.sum(axis=0)\n",
    "        return dW_enc, db_enc, dW_dec, db_dec\n",
    "\n",
    "# Normalize data\n",
    "X_ts_norm = (X_ts - X_ts.mean(axis=1, keepdims=True)) / (X_ts.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "# Split data\n",
    "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(\n",
    "    X_ts_norm, y_ts, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "# Train autoencoder\n",
    "ae = AutoencoderComplete(input_dim=X_train_ts.shape[1], hidden_dim=16, learning_rate=0.05)\n",
    "ae_losses = ae.train(X_train_ts, epochs=30, batch_size=128, verbose=True)\n",
    "\n",
    "# Plot reconstruction quality\n",
    "n_examples = 4\n",
    "fig, axes = plt.subplots(n_examples, 2, figsize=(10, 8))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    idx = i * 100  # Sample different sequences\n",
    "    original = X_test_ts[idx]\n",
    "    reconstructed = ae.reconstruct(original.reshape(1, -1)).flatten()\n",
    "    \n",
    "    axes[i, 0].plot(original, 'b-', label='Original')\n",
    "    axes[i, 0].plot(reconstructed, 'r--', label='Reconstructed')\n",
    "    axes[i, 0].set_ylabel(f\"Seq {idx}\")\n",
    "    axes[i, 0].legend()\n",
    "    axes[i, 0].grid(True)\n",
    "    \n",
    "    axes[i, 1].plot(original - reconstructed, 'g-')\n",
    "    axes[i, 1].set_ylabel(\"Error\")\n",
    "    axes[i, 1].grid(True)\n",
    "    \n",
    "axes[0, 0].set_title(\"Sequence Reconstruction\")\n",
    "axes[0, 1].set_title(\"Reconstruction Error\")\n",
    "axes[-1, 0].set_xlabel(\"Time\")\n",
    "axes[-1, 1].set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning: Classification with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "train_emb = ae.encode(X_train_ts)\n",
    "test_emb = ae.encode(X_test_ts)\n",
    "\n",
    "# Train classifiers\n",
    "clf_emb = LogisticRegression(max_iter=200)\n",
    "clf_emb.fit(train_emb, y_train_ts)\n",
    "emb_acc = clf_emb.score(test_emb, y_test_ts)\n",
    "\n",
    "clf_raw = LogisticRegression(max_iter=200)\n",
    "clf_raw.fit(X_train_ts, y_train_ts)\n",
    "raw_acc = clf_raw.score(X_test_ts, y_test_ts)\n",
    "\n",
    "print(f\"Classification using embeddings: {emb_acc:.3f}\")\n",
    "print(f\"Classification using raw sequences: {raw_acc:.3f}\")\n",
    "print(f\"Dimensionality reduction: {X_train_ts.shape[1]} ‚Üí {train_emb.shape[1]}\")\n",
    "\n",
    "# Visualize embeddings with t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "emb_2d = tsne.fit_transform(test_emb[:300])  # Use subset for speed\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=y_test_ts[:300], cmap='coolwarm', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('Autoencoder Embeddings Visualization')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Advanced Concepts and Extensions\n",
    "\n",
    "### üíª Exercise 5: Implement Contrastive Learning (Advanced)\n",
    "Implement a simple contrastive loss for the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_pairs(X, augmentation_noise=0.1):\n",
    "    \"\"\"\n",
    "    Create positive pairs by adding noise to sequences.\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    - For each sequence, create a positive pair by adding small noise\n",
    "    - Return original, augmented, and labels (1 for positive, 0 for negative)\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    # Positive pairs (same sequence with noise)\n",
    "    X_anchor = X.copy()\n",
    "    X_positive = ___  # FILL: X + noise\n",
    "    \n",
    "    # Negative pairs (different sequences)\n",
    "    # TODO: Create negative pairs by shuffling indices\n",
    "    \n",
    "    return X_anchor, X_positive\n",
    "\n",
    "def contrastive_loss(embeddings1, embeddings2, labels, margin=1.0):\n",
    "    \"\"\"\n",
    "    Compute contrastive loss.\n",
    "    \n",
    "    TODO: Implement the loss\n",
    "    L = y * d^2 + (1-y) * max(0, margin - d)^2\n",
    "    where d is the Euclidean distance between embeddings\n",
    "    \"\"\"\n",
    "    # FILL: Compute pairwise distances\n",
    "    distances = ___\n",
    "    \n",
    "    # FILL: Compute loss\n",
    "    loss = ___\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Skeleton code for testing\n",
    "# X_anchor, X_positive = create_augmented_pairs(X_train_ts[:100])\n",
    "# emb1 = ae.encode(X_anchor)\n",
    "# emb2 = ae.encode(X_positive)\n",
    "# labels = np.ones(len(X_anchor))  # All positive pairs\n",
    "# loss = contrastive_loss(emb1, emb2, labels)\n",
    "# print(f\"Contrastive loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Module: Open-Ended Questions with Gemini Verification\n",
    "\n",
    "This section includes open-ended questions that can be automatically evaluated using the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import requests\n",
    "\n",
    "class OpenEndedAssessment:\n",
    "    \"\"\"Handle open-ended questions with AI verification.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        self.api_key = api_key or os.getenv('GEMINI_API_KEY')\n",
    "        self.questions = self._load_questions()\n",
    "    \n",
    "    def _load_questions(self) -> List[Dict]:\n",
    "        \"\"\"Load assessment questions.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"id\": \"q1\",\n",
    "                \"question\": \"Explain why rotation prediction is an effective pretext task for learning visual features. What properties of the task make it useful?\",\n",
    "                \"rubric\": [\n",
    "                    \"Mentions that rotation is a geometric transformation\",\n",
    "                    \"Notes that it requires understanding object structure\",\n",
    "                    \"Explains that labels are free (self-supervised)\",\n",
    "                    \"Discusses invariance/equivariance properties\"\n",
    "                ],\n",
    "                \"sample_answer\": \"Rotation prediction works because it forces the network to understand spatial structure and object geometry. The task requires recognizing features regardless of orientation, learning rotation-equivariant representations. Labels are automatically generated without human annotation.\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"q2\",\n",
    "                \"question\": \"Compare and contrast autoencoders with contrastive learning methods. When would you choose one over the other?\",\n",
    "                \"rubric\": [\n",
    "                    \"Identifies autoencoders as generative/reconstructive\",\n",
    "                    \"Identifies contrastive as discriminative\",\n",
    "                    \"Mentions computational efficiency differences\",\n",
    "                    \"Discusses use cases for each\"\n",
    "                ],\n",
    "                \"sample_answer\": \"Autoencoders learn by reconstruction, capturing all input details including noise. Contrastive methods learn by comparing samples, focusing on discriminative features. Autoencoders are simpler but may learn trivial solutions. Contrastive methods are more robust but require careful augmentation design.\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"q3\",\n",
    "                \"question\": \"Design a novel pretext task for learning representations from text data. Explain your reasoning.\",\n",
    "                \"rubric\": [\n",
    "                    \"Proposes a specific, implementable task\",\n",
    "                    \"Explains how labels are generated automatically\",\n",
    "                    \"Justifies why the task would learn useful features\",\n",
    "                    \"Considers computational feasibility\"\n",
    "                ],\n",
    "                \"sample_answer\": \"One novel task could be 'sentence ordering': given shuffled sentences from a paragraph, predict the correct order. This requires understanding discourse structure, temporal relationships, and causal dependencies. Labels come from the original ordering, making it fully self-supervised.\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def evaluate_answer(self, question_id: str, user_answer: str) -> Dict:\n",
    "        \"\"\"Evaluate user answer using Gemini API.\"\"\"\n",
    "        question_data = next((q for q in self.questions if q['id'] == question_id), None)\n",
    "        if not question_data:\n",
    "            return {\"error\": \"Question not found\"}\n",
    "        \n",
    "        if not self.api_key:\n",
    "            return self._manual_evaluation(question_data, user_answer)\n",
    "        \n",
    "        # Prepare evaluation prompt\n",
    "        evaluation_prompt = self._create_evaluation_prompt(question_data, user_answer)\n",
    "        \n",
    "        # Call Gemini API\n",
    "        try:\n",
    "            response = self._call_gemini_api(evaluation_prompt)\n",
    "            return self._parse_evaluation(response)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"API call failed: {str(e)}\"}\n",
    "    \n",
    "    def _create_evaluation_prompt(self, question_data: Dict, user_answer: str) -> str:\n",
    "        \"\"\"Create prompt for Gemini evaluation.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following answer to a self-supervised learning question.\n",
    "        \n",
    "        Question: {question_data['question']}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {json.dumps(question_data['rubric'], indent=2)}\n",
    "        \n",
    "        Reference Answer: {question_data['sample_answer']}\n",
    "        \n",
    "        User Answer: {user_answer}\n",
    "        \n",
    "        Please evaluate the answer and provide:\n",
    "        1. Score (0-100)\n",
    "        2. Which rubric points were addressed\n",
    "        3. What was missing or could be improved\n",
    "        4. Any misconceptions to correct\n",
    "        \n",
    "        Format your response as JSON:\n",
    "        {{\n",
    "            \"score\": <number>,\n",
    "            \"rubric_met\": [<list of rubric points addressed>],\n",
    "            \"strengths\": \"<what was done well>\",\n",
    "            \"improvements\": \"<what could be better>\",\n",
    "            \"feedback\": \"<constructive feedback for the student>\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _call_gemini_api(self, prompt: str) -> str:\n",
    "        \"\"\"Call Gemini API for evaluation.\"\"\"\n",
    "        # This is a placeholder - actual implementation would use the Gemini API\n",
    "        # For demonstration, we'll simulate the response\n",
    "        url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={self.api_key}\"\n",
    "        \n",
    "        payload = {\n",
    "            \"contents\": [{\n",
    "                \"parts\": [{\"text\": prompt}]\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        # Simulated response for demonstration\n",
    "        simulated_response = {\n",
    "            \"score\": 85,\n",
    "            \"rubric_met\": [\"Mentions geometric transformation\", \"Explains free labels\"],\n",
    "            \"strengths\": \"Good understanding of core concepts\",\n",
    "            \"improvements\": \"Could discuss invariance properties more\",\n",
    "            \"feedback\": \"Strong answer! Consider exploring how rotation prediction relates to downstream tasks.\"\n",
    "        }\n",
    "        \n",
    "        return json.dumps(simulated_response)\n",
    "    \n",
    "    def _parse_evaluation(self, response: str) -> Dict:\n",
    "        \"\"\"Parse Gemini API response.\"\"\"\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Failed to parse API response\"}\n",
    "    \n",
    "    def _manual_evaluation(self, question_data: Dict, user_answer: str) -> Dict:\n",
    "        \"\"\"Provide manual evaluation guidance when API is not available.\"\"\"\n",
    "        return {\n",
    "            \"message\": \"API key not configured. Please self-evaluate using the rubric.\",\n",
    "            \"rubric\": question_data['rubric'],\n",
    "            \"sample_answer\": question_data['sample_answer'],\n",
    "            \"self_evaluation_guide\": [\n",
    "                \"Compare your answer to the sample\",\n",
    "                \"Check each rubric point\",\n",
    "                \"Award 25 points per rubric item addressed\",\n",
    "                \"Consider partial credit for partially addressed items\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Initialize assessment system\n",
    "assessment = OpenEndedAssessment()\n",
    "\n",
    "# Display questions\n",
    "print(\"üìù Open-Ended Assessment Questions\\n\")\n",
    "for q in assessment.questions:\n",
    "    print(f\"Question {q['id']}: {q['question']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Submission Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_answer(question_id: str, answer: str):\n",
    "    \"\"\"Submit and evaluate an answer.\"\"\"\n",
    "    print(f\"\\nüìä Evaluating answer for question {question_id}...\\n\")\n",
    "    result = assessment.evaluate_answer(question_id, answer)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"‚ùå Error: {result['error']}\")\n",
    "    elif 'message' in result:\n",
    "        print(f\"‚ÑπÔ∏è {result['message']}\\n\")\n",
    "        print(\"Rubric:\")\n",
    "        for item in result['rubric']:\n",
    "            print(f\"  ‚Ä¢ {item}\")\n",
    "        print(f\"\\nSample Answer: {result['sample_answer']}\")\n",
    "    else:\n",
    "        print(f\"Score: {result['score']}/100\")\n",
    "        print(f\"\\n‚úÖ Strengths: {result['strengths']}\")\n",
    "        print(f\"\\nüìà Areas for Improvement: {result['improvements']}\")\n",
    "        print(f\"\\nüí° Feedback: {result['feedback']}\")\n",
    "\n",
    "# Example usage:\n",
    "# submit_answer(\"q1\", \"Rotation prediction helps because...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment Configuration File\n",
    "Save this configuration for external assessment systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assessment configuration\n",
    "assessment_config = {\n",
    "    \"lab_title\": \"Self-Supervised Neural Networks Lab\",\n",
    "    \"version\": \"2.0\",\n",
    "    \"modules\": [\n",
    "        {\n",
    "            \"name\": \"Introduction to SSL\",\n",
    "            \"weight\": 0.2,\n",
    "            \"assessments\": [\"mcq1\", \"q1\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Vision - Rotation Prediction\",\n",
    "            \"weight\": 0.3,\n",
    "            \"assessments\": [\"exercise1\", \"exercise2\", \"mcq2\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Time Series - Autoencoder\",\n",
    "            \"weight\": 0.3,\n",
    "            \"assessments\": [\"exercise4\", \"q2\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Advanced Concepts\",\n",
    "            \"weight\": 0.2,\n",
    "            \"assessments\": [\"exercise5\", \"q3\"]\n",
    "        }\n",
    "    ],\n",
    "    \"grading_scheme\": {\n",
    "        \"exercises\": {\n",
    "            \"exercise1\": {\"points\": 10, \"difficulty\": \"easy\"},\n",
    "            \"exercise2\": {\"points\": 15, \"difficulty\": \"medium\"},\n",
    "            \"exercise3\": {\"points\": 15, \"difficulty\": \"medium-hard\"},\n",
    "            \"exercise4\": {\"points\": 20, \"difficulty\": \"hard\"},\n",
    "            \"exercise5\": {\"points\": 20, \"difficulty\": \"advanced\"}\n",
    "        },\n",
    "        \"mcqs\": {\n",
    "            \"mcq1\": {\"points\": 5},\n",
    "            \"mcq2\": {\"points\": 5}\n",
    "        },\n",
    "        \"open_ended\": {\n",
    "            \"q1\": {\"points\": 10, \"rubric_items\": 4},\n",
    "            \"q2\": {\"points\": 10, \"rubric_items\": 4},\n",
    "            \"q3\": {\"points\": 10, \"rubric_items\": 4}\n",
    "        },\n",
    "        \"total_points\": 120\n",
    "    },\n",
    "    \"api_configuration\": {\n",
    "        \"provider\": \"gemini\",\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "with open('assessment_config.json', 'w') as f:\n",
    "    json.dump(assessment_config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Assessment configuration saved to assessment_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### üéâ Congratulations!\n",
    "You've completed the interactive SSL lab. You've learned:\n",
    "- The principles of self-supervised learning\n",
    "- How to implement pretext tasks (rotation prediction)\n",
    "- Generative SSL with autoencoders\n",
    "- Transfer learning with learned representations\n",
    "- The trade-offs between different SSL approaches\n",
    "\n",
    "### üìö Further Reading\n",
    "1. **Vision SSL:**\n",
    "   - [SimCLR Paper](https://arxiv.org/abs/2002.05709)\n",
    "   - [MoCo Paper](https://arxiv.org/abs/1911.05722)\n",
    "   - [MAE (Masked Autoencoders)](https://arxiv.org/abs/2111.06377)\n",
    "\n",
    "2. **Language SSL:**\n",
    "   - [BERT Paper](https://arxiv.org/abs/1810.04805)\n",
    "   - [GPT Series](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "3. **Time Series SSL:**\n",
    "   - [TS2Vec](https://arxiv.org/abs/2106.10466)\n",
    "   - [TNC (Temporal Neighborhood Coding)](https://arxiv.org/abs/2106.00750)\n",
    "\n",
    "### üöÄ Challenge Extensions\n",
    "1. Implement SimCLR for the digits dataset\n",
    "2. Try masked patch prediction as a pretext task\n",
    "3. Combine multiple pretext tasks (multi-task SSL)\n",
    "4. Apply SSL to your own dataset\n",
    "5. Implement momentum contrast (MoCo)\n",
    "\n",
    "### ü§ù Join the Community\n",
    "- Share your results and implementations\n",
    "- Contribute new pretext tasks\n",
    "- Help improve this lab\n",
    "\n",
    "Remember: SSL is about creativity in finding supervision signals within data itself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}