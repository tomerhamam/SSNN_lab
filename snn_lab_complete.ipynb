{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Supervised Neural Networks: Complete Interactive Lab\n",
    "\n",
    "Welcome to an immersive journey through self-supervised learning! This lab combines theory, hands-on coding, and AI-powered assessment to give you a deep understanding of SSL principles.\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "1. **Understand SSL fundamentals**: Distinguish between generative and discriminative approaches\n",
    "2. **Implement pretext tasks**: Create rotation prediction and autoencoder tasks from scratch\n",
    "3. **Build neural networks**: Implement forward/backward propagation using only NumPy\n",
    "4. **Apply transfer learning**: Use SSL features for downstream classification tasks\n",
    "5. **Analyze representations**: Visualize and interpret learned features\n",
    "6. **Design SSL systems**: Create novel pretext tasks for different domains\n",
    "\n",
    "## ðŸ“š Prerequisites\n",
    "- **Math**: Linear algebra, basic calculus (gradients)\n",
    "- **Programming**: Python, NumPy fundamentals\n",
    "- **ML Basics**: Neural networks, supervised learning concepts\n",
    "\n",
    "## â±ï¸ Expected Duration: ~2 hours\n",
    "- Part 1: Introduction & Setup (15 min)\n",
    "- Part 2: Computer Vision SSL (45 min)  \n",
    "- Part 3: Time Series SSL (30 min)\n",
    "- Part 4: Advanced Concepts (15 min)\n",
    "- Part 5: Assessment & Reflection (15 min)\n",
    "\n",
    "## ðŸ”— Background Reading (Optional)\n",
    "- [Self-supervised Learning Survey](https://arxiv.org/abs/2301.05712)\n",
    "- [Representation Learning Review](https://arxiv.org/abs/1206.5538)\n",
    "\n",
    "Let's begin! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Introduction & Setup (15 minutes)\n",
    "\n",
    "## What is Self-Supervised Learning?\n",
    "\n",
    "**Self-supervised learning (SSL)** is a learning paradigm where models create their own supervision signals from the data structure itself, without requiring human-annotated labels.\n",
    "\n",
    "### The Key Insight\n",
    "Instead of learning from `(input, human_label)` pairs, SSL learns from `(input, automatically_generated_label)` pairs by solving **pretext tasks**.\n",
    "\n",
    "### Two Main Families\n",
    "\n",
    "#### 1. ðŸŽ¨ **Generative/Predictive Methods**\n",
    "- **Goal**: Reconstruct or predict part of the input\n",
    "- **Examples**: Autoencoders, masked language modeling (BERT), image inpainting\n",
    "- **Learning signal**: Reconstruction error\n",
    "\n",
    "#### 2. ðŸ”„ **Discriminative/Contrastive Methods**  \n",
    "- **Goal**: Learn to distinguish between different views of data\n",
    "- **Examples**: SimCLR, MoCo, rotation prediction\n",
    "- **Learning signal**: Similarity/dissimilarity between samples\n",
    "\n",
    "### Why SSL Matters\n",
    "- **Abundant unlabeled data**: Most real-world data lacks labels\n",
    "- **Expensive annotation**: Expert labeling costs time and money\n",
    "- **Better representations**: SSL can learn general features useful across tasks\n",
    "- **Data efficiency**: Reduces labeled data requirements for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"ðŸ”§ Environment setup complete!\")\n",
    "print(f\"ðŸ“Š NumPy version: {np.__version__}\")\n",
    "print(\"ðŸš€ Ready to start learning SSL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 1: Data Exploration (5 minutes)\n",
    "\n",
    "Let's start by exploring our datasets. You'll implement a function to visualize data samples.\n",
    "\n",
    "**Your Task**: Complete the `visualize_samples` function to display a grid of samples with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(images, labels=None, title=\"Sample Visualization\", n_samples=10, figsize=(12, 2)):\n",
    "    \"\"\"\n",
    "    Visualize a grid of image samples.\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    Args:\n",
    "        images: Array of shape (n_samples, height, width) or (n_samples, height*width)\n",
    "        labels: Optional labels for each image\n",
    "        title: Plot title\n",
    "        n_samples: Number of samples to show\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    # Ensure we don't try to show more samples than available\n",
    "    n_show = min(n_samples, len(images))\n",
    "    \n",
    "    # TODO: Create figure and subplots\n",
    "    fig, axes = plt.subplots(___) # FILL: 1 row, n_show columns, figsize=figsize\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if n_show == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        # TODO: Get the image and reshape if needed\n",
    "        img = images[i]\n",
    "        if len(img.shape) == 1:  # If flattened\n",
    "            img = img.reshape(___) # FILL: Reshape to (8, 8) for digits\n",
    "        \n",
    "        # TODO: Display the image\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        \n",
    "        # TODO: Set title with label if provided\n",
    "        if labels is not None:\n",
    "            axes[i].set_title(___) # FILL: f\"Label: {labels[i]}\"\n",
    "        \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test your implementation\n",
    "digits = load_digits()\n",
    "print(f\"ðŸ“Š Dataset loaded: {digits.data.shape[0]} samples, {digits.data.shape[1]} features\")\n",
    "print(f\"ðŸ”¢ Classes: {np.unique(digits.target)}\")\n",
    "\n",
    "# TODO: Uncomment to test your visualization function\n",
    "# visualize_samples(digits.images, digits.target, \"Handwritten Digits Dataset\", n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Solution Check\n",
    "If your implementation is correct, you should see a row of 10 digit images with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (run this cell if you need help)\n",
    "def visualize_samples_solution(images, labels=None, title=\"Sample Visualization\", n_samples=10, figsize=(12, 2)):\n",
    "    \"\"\"Reference implementation for visualization function.\"\"\"\n",
    "    n_show = min(n_samples, len(images))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_show, figsize=figsize)\n",
    "    \n",
    "    if n_show == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        img = images[i]\n",
    "        if len(img.shape) == 1:\n",
    "            img = img.reshape(8, 8)\n",
    "        \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        \n",
    "        if labels is not None:\n",
    "            axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test the solution\n",
    "visualize_samples_solution(digits.images, digits.target, \"Handwritten Digits - Solution\", n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Critical Thinking Question 1\n",
    "\n",
    "**Looking at these 8Ã—8 pixel images, why do you think such low resolution is sufficient for humans to recognize digits? What does this tell us about the kind of features a neural network needs to learn?**\n",
    "\n",
    "*Think about: shape, edges, structure, and what makes each digit distinctive.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Computer Vision SSL - Rotation Prediction (45 minutes)\n",
    "\n",
    "Now we'll implement our first SSL system using **rotation prediction** as a pretext task.\n",
    "\n",
    "## The Big Picture\n",
    "1. **Pretext Task**: Train a network to predict image rotations (0Â°, 90Â°, 180Â°, 270Â°)\n",
    "2. **Feature Learning**: Network learns spatial features to solve rotation task\n",
    "3. **Transfer Learning**: Use learned features for digit classification\n",
    "4. **Evaluation**: Compare SSL features vs raw pixels\n",
    "\n",
    "## Why Rotation Prediction Works\n",
    "- **Geometric Understanding**: Requires understanding object structure and orientation\n",
    "- **Rich Features**: Forces network to learn rotation-equivariant representations  \n",
    "- **Free Labels**: Can generate unlimited rotation labels automatically\n",
    "- **General Purpose**: Features useful for many downstream vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 2: Create Rotation Dataset (10 minutes)\n",
    "\n",
    "First, let's create our pretext task dataset by generating rotated versions of images.\n",
    "\n",
    "**Your Task**: Complete the rotation dataset creation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotation_dataset(X: np.ndarray, rotations: Tuple[int, ...] = (0, 90, 180, 270)) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create a dataset of rotated images for the pretext task.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of flattened images, shape (n_samples, 64)\n",
    "        rotations: Tuple of rotation angles in degrees\n",
    "    \n",
    "    Returns:\n",
    "        rot_X: Array of rotated images, shape (n_samples * len(rotations), 64)\n",
    "        rot_y: Array of rotation labels, shape (n_samples * len(rotations),)\n",
    "    \"\"\"\n",
    "    # TODO: Reshape flattened images back to 8x8\n",
    "    images = X.reshape(___) # FILL: (-1, 8, 8)\n",
    "    \n",
    "    rot_images = []\n",
    "    rot_labels = []\n",
    "    \n",
    "    for idx, angle in enumerate(rotations):\n",
    "        # TODO: Calculate number of 90-degree rotations needed\n",
    "        # Hint: np.rot90 rotates by 90 degrees k times\n",
    "        k = ___  # FILL: (angle // 90) % 4\n",
    "        \n",
    "        for img in images:\n",
    "            # TODO: Rotate the image k times by 90 degrees\n",
    "            rotated = ___  # FILL: np.rot90(img, k=k)\n",
    "            \n",
    "            # TODO: Flatten and add to lists\n",
    "            rot_images.append(___) # FILL: rotated.flatten()\n",
    "            rot_labels.append(___) # FILL: idx (rotation class index)\n",
    "    \n",
    "    return np.array(rot_images, dtype=np.float32), np.array(rot_labels, dtype=np.int64)\n",
    "\n",
    "# Load and normalize digit data\n",
    "digits = load_digits()\n",
    "X = digits.data.astype(np.float32) / 16.0  # Normalize to [0, 1]\n",
    "y = digits.target\n",
    "\n",
    "print(f\"ðŸ“Š Original dataset: {X.shape}\")\n",
    "print(f\"ðŸŽ¯ Original classes: {len(np.unique(y))} digits (0-9)\")\n",
    "\n",
    "# TODO: Create rotation dataset using first 100 samples for testing\n",
    "# rot_X, rot_y = create_rotation_dataset(X[:100])\n",
    "# print(f\"ðŸ”„ Rotation dataset: {rot_X.shape}\")\n",
    "# print(f\"ðŸ·ï¸ Rotation classes: {np.unique(rot_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the rotations to check our implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution and visualization\n",
    "def create_rotation_dataset_solution(X: np.ndarray, rotations: Tuple[int, ...] = (0, 90, 180, 270)) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    images = X.reshape(-1, 8, 8)\n",
    "    rot_images = []\n",
    "    rot_labels = []\n",
    "    \n",
    "    for idx, angle in enumerate(rotations):\n",
    "        k = (angle // 90) % 4\n",
    "        for img in images:\n",
    "            rotated = np.rot90(img, k=k)\n",
    "            rot_images.append(rotated.flatten())\n",
    "            rot_labels.append(idx)\n",
    "    \n",
    "    return np.array(rot_images, dtype=np.float32), np.array(rot_labels, dtype=np.int64)\n",
    "\n",
    "# Create rotation dataset\n",
    "rot_X, rot_y = create_rotation_dataset_solution(X[:100])\n",
    "print(f\"ðŸ”„ Rotation dataset shape: {rot_X.shape}\")\n",
    "print(f\"ðŸ·ï¸ Rotation labels: {np.unique(rot_y)} (0=0Â°, 1=90Â°, 2=180Â°, 3=270Â°)\")\n",
    "\n",
    "# Visualize rotations of a single digit\n",
    "sample_idx = 0  # First digit\n",
    "rotations = [0, 90, 180, 270]\n",
    "sample_rotations = []\n",
    "\n",
    "for i in range(4):\n",
    "    # Each rotation class contains the same digit rotated differently\n",
    "    rot_sample_idx = sample_idx + i * 100  # 100 original samples per rotation\n",
    "    sample_rotations.append(rot_X[rot_sample_idx])\n",
    "\n",
    "visualize_samples_solution(\n",
    "    sample_rotations, \n",
    "    [f\"{angle}Â°\" for angle in rotations],\n",
    "    f\"Rotations of Digit {y[sample_idx]}\", \n",
    "    n_samples=4,\n",
    "    figsize=(8, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 3: Neural Network Implementation (15 minutes)\n",
    "\n",
    "Now we'll implement a simple 2-layer neural network from scratch to solve the rotation prediction task.\n",
    "\n",
    "**Your Task**: Complete the forward pass and key methods of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TwoLayerNet:\n",
    "    \"\"\"A simple two-layer neural network for rotation prediction.\"\"\"\n",
    "    input_dim: int\n",
    "    hidden_dim: int  \n",
    "    output_dim: int\n",
    "    learning_rate: float = 0.5\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize network parameters.\"\"\"\n",
    "        # Use fixed seed for reproducible results\n",
    "        rng = np.random.default_rng(0)\n",
    "        \n",
    "        # TODO: Initialize weights and biases\n",
    "        # Hint: Use small random weights (multiply by 0.01) and zero biases\n",
    "        self.W1 = rng.standard_normal((___)) * 0.01 # FILL: (self.input_dim, self.hidden_dim)\n",
    "        self.b1 = np.zeros(___) # FILL: self.hidden_dim\n",
    "        self.W2 = rng.standard_normal((___)) * 0.01 # FILL: (self.hidden_dim, self.output_dim) \n",
    "        self.b2 = np.zeros(___) # FILL: self.output_dim\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> Tuple[np.ndarray, Tuple]:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        # TODO: Implement forward pass\n",
    "        # Layer 1: Linear transformation + tanh activation\n",
    "        z1 = ___  # FILL: X @ self.W1 + self.b1\n",
    "        a1 = ___  # FILL: np.tanh(z1)\n",
    "        \n",
    "        # Layer 2: Linear transformation\n",
    "        z2 = ___  # FILL: a1 @ self.W2 + self.b2\n",
    "        \n",
    "        # Softmax activation (numerically stable)\n",
    "        exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
    "        probs = exp_scores / exp_scores.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        # Cache intermediate values for backprop\n",
    "        cache = (X, z1, a1, z2, probs)\n",
    "        return probs, cache\n",
    "    \n",
    "    def backward(self, cache, y_true: np.ndarray):\n",
    "        \"\"\"Backward pass (backpropagation) - provided for you.\"\"\"\n",
    "        X, z1, a1, z2, probs = cache\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Convert labels to one-hot encoding\n",
    "        one_hot = np.zeros_like(probs)\n",
    "        one_hot[np.arange(n_samples), y_true] = 1\n",
    "        \n",
    "        # Gradients for output layer\n",
    "        dz2 = (probs - one_hot) / n_samples\n",
    "        dW2 = a1.T @ dz2\n",
    "        db2 = dz2.sum(axis=0)\n",
    "        \n",
    "        # Gradients for hidden layer\n",
    "        da1 = dz2 @ self.W2.T\n",
    "        dz1 = da1 * (1.0 - np.tanh(z1)**2)  # derivative of tanh\n",
    "        dW1 = X.T @ dz1\n",
    "        db1 = dz1.sum(axis=0)\n",
    "        \n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    def update_params(self, dW1, db1, dW2, db2):\n",
    "        \"\"\"Update parameters using gradients.\"\"\"\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "    \n",
    "    def train(self, X, y, epochs=20, batch_size=128, verbose=True):\n",
    "        \"\"\"Train the network using mini-batch gradient descent.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle data\n",
    "            idx = np.random.permutation(n_samples)\n",
    "            X_shuf, y_shuf = X[idx], y[idx]\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            n_batches = 0\n",
    "            \n",
    "            # Mini-batch training\n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                X_batch = X_shuf[start:end]\n",
    "                y_batch = y_shuf[start:end]\n",
    "                \n",
    "                # Forward pass\n",
    "                probs, cache = self.forward(X_batch)\n",
    "                \n",
    "                # Calculate loss\n",
    "                batch_loss = -np.log(probs[np.arange(len(y_batch)), y_batch] + 1e-8).mean()\n",
    "                epoch_loss += batch_loss\n",
    "                n_batches += 1\n",
    "                \n",
    "                # Backward pass and parameter update\n",
    "                grads = self.backward(cache, y_batch)\n",
    "                self.update_params(*grads)\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            train_acc = self.evaluate(X, y)\n",
    "            accuracies.append(train_acc)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch {epoch+1:2d}/{epochs}: Loss = {avg_loss:.4f}, Accuracy = {train_acc:.3f}\")\n",
    "        \n",
    "        return losses, accuracies\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        probs, _ = self.forward(X)\n",
    "        return probs.argmax(axis=1)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Evaluate accuracy on given data.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return (predictions == y).mean()\n",
    "    \n",
    "    def hidden_representation(self, X):\n",
    "        \"\"\"Extract hidden layer features for transfer learning.\"\"\"\n",
    "        z1 = X @ self.W1 + self.b1\n",
    "        return np.tanh(z1)\n",
    "\n",
    "# Test network initialization\n",
    "print(\"ðŸ§  Testing network initialization...\")\n",
    "test_net = TwoLayerNet(input_dim=64, hidden_dim=32, output_dim=4, learning_rate=0.3)\n",
    "print(f\"âœ… Network created: {test_net.input_dim} â†’ {test_net.hidden_dim} â†’ {test_net.output_dim}\")\n",
    "print(f\"ðŸ“Š Weight shapes: W1={test_net.W1.shape}, W2={test_net.W2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Quick Test: Forward Pass\n",
    "Let's test if your forward pass implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass with small batch\n",
    "test_input = rot_X[:5]  # 5 samples\n",
    "probs, cache = test_net.forward(test_input)\n",
    "\n",
    "print(f\"âœ… Forward pass successful!\")\n",
    "print(f\"ðŸ“Š Input shape: {test_input.shape}\")\n",
    "print(f\"ðŸ“Š Output probabilities shape: {probs.shape}\")\n",
    "print(f\"ðŸŽ¯ Probability sums (should be ~1.0): {probs.sum(axis=1)}\")\n",
    "print(f\"ðŸ” Sample predictions: {probs.argmax(axis=1)}\")\n",
    "\n",
    "# Verify probabilities sum to 1\n",
    "assert np.allclose(probs.sum(axis=1), 1.0), \"Probabilities should sum to 1!\"\n",
    "print(\"âœ… Forward pass test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 4: Train the Rotation Classifier (10 minutes)\n",
    "\n",
    "Now let's train our network on the rotation prediction task!\n",
    "\n",
    "**Your Task**: Set up training and evaluate the rotation classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full rotation dataset\n",
    "print(\"ðŸ”„ Creating full rotation dataset...\")\n",
    "rot_X, rot_y = create_rotation_dataset_solution(X)  # Use all samples\n",
    "print(f\"ðŸ“Š Full rotation dataset: {rot_X.shape}\")\n",
    "\n",
    "# TODO: Split into training and validation sets\n",
    "# Hint: Use 80/20 split with random_state=42 for reproducibility\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    ___,  # FILL: rot_X\n",
    "    ___,  # FILL: rot_y\n",
    "    test_size=___,  # FILL: 0.2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Training set: {X_train.shape}\")\n",
    "print(f\"ðŸ“Š Validation set: {X_val.shape}\")\n",
    "\n",
    "# TODO: Create and configure the network\n",
    "# Hint: Use input_dim=64, hidden_dim=32, output_dim=4\n",
    "net = TwoLayerNet(\n",
    "    input_dim=___,  # FILL: 64\n",
    "    hidden_dim=___,  # FILL: 32\n",
    "    output_dim=___,  # FILL: 4\n",
    "    learning_rate=0.3\n",
    ")\n",
    "\n",
    "print(\"\\nðŸš€ Starting training...\")\n",
    "\n",
    "# TODO: Train the network\n",
    "# Hint: Use 15 epochs, batch_size=256\n",
    "# losses, accuracies = net.train(X_train, y_train, epochs=___, batch_size=___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Train the network\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    rot_X, rot_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "net = TwoLayerNet(input_dim=64, hidden_dim=32, output_dim=4, learning_rate=0.3)\n",
    "\n",
    "print(\"ðŸš€ Training rotation classifier...\")\n",
    "losses, accuracies = net.train(X_train, y_train, epochs=15, batch_size=256)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_acc = net.evaluate(X_val, y_val)\n",
    "print(f\"\\nðŸŽ¯ Final validation accuracy: {val_acc:.3f}\")\n",
    "\n",
    "# Check if we beat random guessing (25% for 4 classes)\n",
    "if val_acc > 0.25:\n",
    "    print(f\"âœ… Great! We beat random guessing (25%)\")\n",
    "    if val_acc > 0.5:\n",
    "        print(f\"ðŸŽ‰ Excellent! The network learned meaningful rotation features!\")\nelse:\n",
    "    print(f\"âŒ Hmm, we didn't beat random guessing. Try adjusting hyperparameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(losses, 'b-', linewidth=2, label='Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Cross-Entropy Loss')\n",
    "ax1.set_title('Training Loss Over Time')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(accuracies, 'g-', linewidth=2, label='Training Accuracy')\n",
    "ax2.axhline(y=0.25, color='r', linestyle='--', alpha=0.7, label='Random Guess (25%)')\n",
    "ax2.axhline(y=val_acc, color='orange', linestyle='--', alpha=0.7, label=f'Final Val Acc ({val_acc:.3f})')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy Over Time')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“Š Training Summary:\")\n",
    "print(f\"   â€¢ Final training accuracy: {accuracies[-1]:.3f}\")\n",
    "print(f\"   â€¢ Final validation accuracy: {val_acc:.3f}\")\n",
    "print(f\"   â€¢ Improvement over random: {(val_acc - 0.25) * 100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 5: Transfer Learning Analysis (10 minutes)\n",
    "\n",
    "The real test of SSL: Can we use the learned features for a different task?\n",
    "\n",
    "**Your Task**: Extract features and compare SSL vs baseline performance on digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Setting up transfer learning experiment...\")\n",
    "\n",
    "# TODO: Extract hidden features for all original digits\n",
    "ssl_features = ___  # FILL: net.hidden_representation(X)\n",
    "\n",
    "print(f\"ðŸ“Š Original digit data: {X.shape}\")\n",
    "print(f\"ðŸ§  SSL features: {ssl_features.shape}\")\n",
    "print(f\"ðŸ“‰ Dimensionality reduction: {X.shape[1]} â†’ {ssl_features.shape[1]} features\")\n",
    "\n",
    "# TODO: Split data for downstream classification\n",
    "# Create train/test splits for both SSL features and raw pixels\n",
    "X_train_ssl, X_test_ssl, y_train_ssl, y_test_ssl = train_test_split(\n",
    "    ___,  # FILL: ssl_features\n",
    "    ___,  # FILL: y  \n",
    "    test_size=0.3,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    ___,  # FILL: X\n",
    "    ___,  # FILL: y\n",
    "    test_size=0.3, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Downstream task splits:\")\n",
    "print(f\"   â€¢ SSL features train/test: {X_train_ssl.shape} / {X_test_ssl.shape}\")\n",
    "print(f\"   â€¢ Raw pixels train/test: {X_train_raw.shape} / {X_test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution and training\n",
    "ssl_features = net.hidden_representation(X)\n",
    "\n",
    "X_train_ssl, X_test_ssl, y_train_ssl, y_test_ssl = train_test_split(\n",
    "    ssl_features, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Training downstream classifiers...\")\n",
    "\n",
    "# Train classifier on SSL features\n",
    "clf_ssl = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_ssl.fit(X_train_ssl, y_train_ssl)\n",
    "ssl_acc = clf_ssl.score(X_test_ssl, y_test_ssl)\n",
    "\n",
    "# Train baseline classifier on raw pixels\n",
    "clf_baseline = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_baseline.fit(X_train_raw, y_train_raw)\n",
    "baseline_acc = clf_baseline.score(X_test_raw, y_test_raw)\n",
    "\n",
    "print(f\"\\nðŸ“Š Transfer Learning Results:\")\n",
    "print(f\"   ðŸ§  SSL Features Accuracy: {ssl_acc:.3f}\")\n",
    "print(f\"   ðŸ“¸ Raw Pixels Accuracy: {baseline_acc:.3f}\")\n",
    "print(f\"   ðŸ“ˆ SSL vs Baseline: {(ssl_acc - baseline_acc)*100:+.1f} percentage points\")\n",
    "\n",
    "if ssl_acc > baseline_acc:\n",
    "    print(f\"   âœ… SSL features outperform raw pixels!\")\n",
    "elif abs(ssl_acc - baseline_acc) < 0.02:\n",
    "    print(f\"   ðŸ“Š SSL features perform similarly to raw pixels\")\n",
    "else:\n",
    "    print(f\"   ðŸ“ Raw pixels perform better (dataset might be too simple for SSL to shine)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Detailed Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed performance comparison\n",
    "ssl_pred = clf_ssl.predict(X_test_ssl)\n",
    "baseline_pred = clf_baseline.predict(X_test_raw)\n",
    "\n",
    "# Confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# SSL features confusion matrix\n",
    "cm_ssl = confusion_matrix(y_test_ssl, ssl_pred)\n",
    "sns.heatmap(cm_ssl, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
    "ax1.set_title(f'SSL Features (Acc: {ssl_acc:.3f})')\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('True')\n",
    "\n",
    "# Baseline confusion matrix  \n",
    "cm_baseline = confusion_matrix(y_test_raw, baseline_pred)\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Oranges', ax=ax2, cbar=False)\n",
    "ax2.set_title(f'Raw Pixels (Acc: {baseline_acc:.3f})')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class performance\n",
    "print(\"\\nðŸ“Š Per-class Performance Comparison:\")\n",
    "print(\"\\nSSL Features:\")\n",
    "print(classification_report(y_test_ssl, ssl_pred, target_names=[str(i) for i in range(10)]))\n",
    "\n",
    "print(\"\\nRaw Pixels:\")\n",
    "print(classification_report(y_test_raw, baseline_pred, target_names=[str(i) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Critical Thinking Question 2\n",
    "\n",
    "**Looking at the results, why might SSL features sometimes underperform raw pixels on this simple dataset? In what scenarios would you expect SSL to provide bigger advantages?**\n",
    "\n",
    "*Think about: dataset complexity, label availability, domain shift, and the information bottleneck.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Multiple Choice Question 1\n",
    "**What is the main advantage of using rotation prediction as a pretext task?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleChoiceQuestion:\n",
    "    def __init__(self, question, options, correct_answer, explanation):\n",
    "        self.question = question\n",
    "        self.options = options\n",
    "        self.correct_answer = correct_answer\n",
    "        self.explanation = explanation\n",
    "    \n",
    "    def display(self):\n",
    "        print(f\"â“ {self.question}\\n\")\n",
    "        for i, option in enumerate(self.options, 1):\n",
    "            print(f\"{i}. {option}\")\n",
    "        print(\"\\nEnter your answer (1-4):\")\n",
    "    \n",
    "    def check_answer(self, answer):\n",
    "        if answer == self.correct_answer:\n",
    "            print(\"âœ… Correct!\")\n",
    "        else:\n",
    "            print(f\"âŒ Incorrect. The correct answer is {self.correct_answer}.\")\n",
    "        print(f\"\\nðŸ’¡ Explanation: {self.explanation}\")\n",
    "\n",
    "mcq1 = MultipleChoiceQuestion(\n",
    "    \"What is the main advantage of using rotation prediction as a pretext task?\",\n",
    "    [\n",
    "        \"It's computationally very fast to train\",\n",
    "        \"It forces the network to learn geometric and spatial features\",\n",
    "        \"It works only on handwritten digits\",\n",
    "        \"It requires very little data to be effective\"\n",
    "    ],\n",
    "    2,\n",
    "    \"Rotation prediction forces the network to understand spatial relationships and geometric transformations, leading to features that capture object structure and orientation - useful for many vision tasks.\"\n",
    ")\n",
    "\n",
    "mcq1.display()\n",
    "\n",
    "# Uncomment to check your answer:\n",
    "# mcq1.check_answer(2)  # Replace 2 with your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Time Series SSL - Autoencoder (30 minutes)\n",
    "\n",
    "Now let's explore **generative SSL** using autoencoders on time series data.\n",
    "\n",
    "## The Big Picture\n",
    "1. **Generate Data**: Create synthetic sine waves with different frequencies\n",
    "2. **Pretext Task**: Train autoencoder to reconstruct sequences (unsupervised)\n",
    "3. **Feature Learning**: Extract compressed representations from encoder\n",
    "4. **Transfer Learning**: Use embeddings for frequency classification\n",
    "5. **Analysis**: Compare autoencoder features vs raw sequences\n",
    "\n",
    "## Why Autoencoders Work for SSL\n",
    "- **Compression Forces Learning**: Bottleneck forces model to capture essential features\n",
    "- **Reconstruction Objective**: Learn to preserve important signal characteristics\n",
    "- **Unsupervised**: No labels needed for the pretext task\n",
    "- **Denoising Effect**: Can learn robust representations from noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 6: Synthetic Time Series Generation (5 minutes)\n",
    "\n",
    "First, let's create our synthetic time series dataset.\n",
    "\n",
    "**Your Task**: Implement a function to generate sine wave sequences with different frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_sequences(n_samples=1000, length=50, freq0=1.0, freq1=3.0, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic sine wave sequences with two different frequencies.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Total number of sequences to generate\n",
    "        length: Length of each sequence (time steps)\n",
    "        freq0: Frequency for class 0 (lower frequency)\n",
    "        freq1: Frequency for class 1 (higher frequency) \n",
    "        noise_std: Standard deviation of Gaussian noise to add\n",
    "    \n",
    "    Returns:\n",
    "        X: Array of sequences, shape (n_samples, length)\n",
    "        y: Array of frequency labels, shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # TODO: Create time vector from 0 to 2Ï€\n",
    "    t = np.linspace(___) # FILL: (0, 2 * np.pi, length)\n",
    "    \n",
    "    # Split samples between two classes\n",
    "    half = n_samples // 2\n",
    "    \n",
    "    # TODO: Generate class 0 sequences (low frequency)\n",
    "    seq0 = np.sin(___) # FILL: freq0 * t\n",
    "    seq0 = np.tile(seq0, (half, 1))  # Repeat for half the samples\n",
    "    \n",
    "    # TODO: Generate class 1 sequences (high frequency)\n",
    "    seq1 = np.sin(___) # FILL: freq1 * t\n",
    "    seq1 = np.tile(seq1, (n_samples - half, 1))  # Repeat for remaining samples\n",
    "    \n",
    "    # Combine sequences\n",
    "    X = np.concatenate([seq0, seq1], axis=0)\n",
    "    \n",
    "    # TODO: Add Gaussian noise\n",
    "    X += np.random.normal(___) # FILL: scale=noise_std, size=X.shape\n",
    "    \n",
    "    # Create labels\n",
    "    y = np.concatenate([\n",
    "        np.zeros(half, dtype=int),  # Class 0 \n",
    "        np.ones(n_samples - half, dtype=int)  # Class 1\n",
    "    ])\n",
    "    \n",
    "    return X.astype(np.float32), y\n",
    "\n",
    "# TODO: Generate test data\n",
    "print(\"ðŸŒŠ Generating synthetic time series...\")\n",
    "# X_ts, y_ts = generate_sine_sequences(n_samples=1000, length=50, freq0=1.0, freq1=3.0, noise_std=0.1)\n",
    "# print(f\"ðŸ“Š Time series data: {X_ts.shape}\")\n",
    "# print(f\"ðŸ·ï¸ Class distribution: {np.bincount(y_ts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution and visualization\n",
    "def generate_sine_sequences_solution(n_samples=1000, length=50, freq0=1.0, freq1=3.0, noise_std=0.1):\n",
    "    t = np.linspace(0, 2 * np.pi, length)\n",
    "    half = n_samples // 2\n",
    "    \n",
    "    seq0 = np.sin(freq0 * t)\n",
    "    seq0 = np.tile(seq0, (half, 1))\n",
    "    \n",
    "    seq1 = np.sin(freq1 * t)\n",
    "    seq1 = np.tile(seq1, (n_samples - half, 1))\n",
    "    \n",
    "    X = np.concatenate([seq0, seq1], axis=0)\n",
    "    X += np.random.normal(scale=noise_std, size=X.shape)\n",
    "    \n",
    "    y = np.concatenate([\n",
    "        np.zeros(half, dtype=int),\n",
    "        np.ones(n_samples - half, dtype=int)\n",
    "    ])\n",
    "    \n",
    "    return X.astype(np.float32), y\n",
    "\n",
    "# Generate data\n",
    "X_ts, y_ts = generate_sine_sequences_solution(n_samples=1000, length=50, freq0=1.0, freq1=3.0, noise_std=0.1)\n",
    "print(f\"ðŸŒŠ Generated time series: {X_ts.shape}\")\n",
    "print(f\"ðŸ·ï¸ Class 0 (freq=1.0): {np.sum(y_ts == 0)} samples\")\n",
    "print(f\"ðŸ·ï¸ Class 1 (freq=3.0): {np.sum(y_ts == 1)} samples\")\n",
    "\n",
    "# Visualize examples from each class\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(3):\n",
    "    plt.plot(X_ts[i], alpha=0.7, label=f\"Sample {i+1}\")\n",
    "plt.title(f\"Class 0: Low Frequency (freq={1.0})\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(3):\n",
    "    idx = len(X_ts) - i - 1  # Get samples from class 1\n",
    "    plt.plot(X_ts[idx], alpha=0.7, label=f\"Sample {i+1}\")\n",
    "plt.title(f\"Class 1: High Frequency (freq={3.0})\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 7: Implement Autoencoder (15 minutes)\n",
    "\n",
    "Now let's implement a simple autoencoder for sequence reconstruction.\n",
    "\n",
    "**Your Task**: Complete the autoencoder implementation, focusing on the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass  \n",
    "class Autoencoder:\n",
    "    \"\"\"Simple autoencoder for time series reconstruction.\"\"\"\n",
    "    input_dim: int\n",
    "    hidden_dim: int\n",
    "    learning_rate: float = 0.1\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize encoder and decoder parameters.\"\"\"\n",
    "        rng = np.random.default_rng(1)  # Different seed from vision network\n",
    "        \n",
    "        # Encoder parameters\n",
    "        self.W_enc = rng.standard_normal((self.input_dim, self.hidden_dim)) * 0.05\n",
    "        self.b_enc = np.zeros(self.hidden_dim)\n",
    "        \n",
    "        # Decoder parameters  \n",
    "        self.W_dec = rng.standard_normal((self.hidden_dim, self.input_dim)) * 0.05\n",
    "        self.b_dec = np.zeros(self.input_dim)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: encode then decode.\"\"\"\n",
    "        # Encoder: compress input to hidden representation\n",
    "        z = X @ self.W_enc + self.b_enc\n",
    "        h = np.tanh(z)  # Hidden representation\n",
    "        \n",
    "        # Decoder: reconstruct from hidden representation\n",
    "        recon = h @ self.W_dec + self.b_dec\n",
    "        \n",
    "        return h, recon\n",
    "    \n",
    "    def compute_loss(self, X, recon):\n",
    "        \"\"\"Compute mean squared error reconstruction loss.\"\"\"\n",
    "        # TODO: Implement MSE loss\n",
    "        # Hint: MSE = mean((X - recon)^2)\n",
    "        loss = ___  # FILL: np.mean((X - recon)**2)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, h, recon):\n",
    "        \"\"\"\n",
    "        Compute gradients for autoencoder parameters.\n",
    "        \n",
    "        This is the key exercise - implement backpropagation for reconstruction loss!\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # TODO: Gradient of loss w.r.t. reconstruction\n",
    "        # Hint: For MSE loss, d_loss/d_recon = 2 * (recon - X) / n_samples\n",
    "        d_recon = ___  # FILL: 2 * (recon - X) / n_samples\n",
    "        \n",
    "        # TODO: Decoder gradients\n",
    "        # Hint: recon = h @ W_dec + b_dec\n",
    "        dW_dec = ___  # FILL: h.T @ d_recon\n",
    "        db_dec = ___  # FILL: d_recon.sum(axis=0)\n",
    "        \n",
    "        # TODO: Propagate gradients to hidden layer\n",
    "        # Hint: Chain rule through decoder weights\n",
    "        dh = ___  # FILL: d_recon @ self.W_dec.T\n",
    "        \n",
    "        # TODO: Gradient through tanh activation\n",
    "        # Hint: d_tanh/d_z = 1 - tanh^2(z)\n",
    "        dz = dh * (1.0 - h**2)\n",
    "        \n",
    "        # TODO: Encoder gradients  \n",
    "        # Hint: z = X @ W_enc + b_enc\n",
    "        dW_enc = ___  # FILL: X.T @ dz\n",
    "        db_enc = ___  # FILL: dz.sum(axis=0)\n",
    "        \n",
    "        return dW_enc, db_enc, dW_dec, db_dec\n",
    "    \n",
    "    def update_params(self, dW_enc, db_enc, dW_dec, db_dec):\n",
    "        \"\"\"Update parameters using gradients.\"\"\"\n",
    "        self.W_enc -= self.learning_rate * dW_enc\n",
    "        self.b_enc -= self.learning_rate * db_enc\n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.b_dec -= self.learning_rate * db_dec\n",
    "    \n",
    "    def train(self, X, epochs=30, batch_size=64, verbose=True):\n",
    "        \"\"\"Train the autoencoder.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle data\n",
    "            idx = np.random.permutation(n_samples)\n",
    "            X_shuf = X[idx]\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            n_batches = 0\n",
    "            \n",
    "            # Mini-batch training\n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                X_batch = X_shuf[start:end]\n",
    "                \n",
    "                # Forward pass\n",
    "                h, recon = self.forward(X_batch)\n",
    "                loss = self.compute_loss(X_batch, recon)\n",
    "                \n",
    "                # Backward pass and update\n",
    "                grads = self.backward(X_batch, h, recon)\n",
    "                self.update_params(*grads)\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                n_batches += 1\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1:2d}/{epochs}: MSE Loss = {avg_loss:.6f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def encode(self, X):\n",
    "        \"\"\"Extract hidden representations (encoder only).\"\"\"\n",
    "        z = X @ self.W_enc + self.b_enc\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\"Reconstruct input sequences.\"\"\"\n",
    "        h = self.encode(X)\n",
    "        return h @ self.W_dec + self.b_dec\n",
    "\n",
    "print(\"ðŸ”§ Autoencoder class implemented!\")\n",
    "print(\"ðŸ“ Next: Complete the backward pass implementation above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Test Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autoencoder initialization and forward pass\n",
    "print(\"ðŸ§ª Testing autoencoder implementation...\")\n",
    "\n",
    "# Create small test autoencoder\n",
    "test_ae = Autoencoder(input_dim=50, hidden_dim=16, learning_rate=0.05)\n",
    "print(f\"âœ… Autoencoder created: {test_ae.input_dim} â†’ {test_ae.hidden_dim} â†’ {test_ae.input_dim}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_data = X_ts[:5]  # 5 test sequences\n",
    "h, recon = test_ae.forward(test_data)\n",
    "print(f\"âœ… Forward pass successful!\")\n",
    "print(f\"   Input shape: {test_data.shape}\")\n",
    "print(f\"   Hidden shape: {h.shape}\")\n",
    "print(f\"   Reconstruction shape: {recon.shape}\")\n",
    "\n",
    "# Test loss computation\n",
    "loss = test_ae.compute_loss(test_data, recon)\n",
    "print(f\"âœ… Loss computation: {loss:.6f}\")\n",
    "\n",
    "# TODO: Uncomment to test your backward pass implementation\n",
    "# grads = test_ae.backward(test_data, h, recon)\n",
    "# print(f\"âœ… Backward pass successful!\")\n",
    "# print(f\"   Gradient shapes: dW_enc={grads[0].shape}, dW_dec={grads[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for backward pass - complete implementation\n",
    "class AutoencoderComplete(Autoencoder):\n",
    "    def compute_loss(self, X, recon):\n",
    "        return np.mean((X - recon)**2)\n",
    "    \n",
    "    def backward(self, X, h, recon):\n",
    "        n_samples = X.shape[0]\n",
    "        d_recon = 2 * (recon - X) / n_samples\n",
    "        dW_dec = h.T @ d_recon\n",
    "        db_dec = d_recon.sum(axis=0)\n",
    "        dh = d_recon @ self.W_dec.T\n",
    "        dz = dh * (1.0 - h**2)\n",
    "        dW_enc = X.T @ dz\n",
    "        db_enc = dz.sum(axis=0)\n",
    "        return dW_enc, db_enc, dW_dec, db_dec\n",
    "\n",
    "# Test complete implementation\n",
    "test_ae_complete = AutoencoderComplete(input_dim=50, hidden_dim=16, learning_rate=0.05)\n",
    "h, recon = test_ae_complete.forward(test_data)\n",
    "grads = test_ae_complete.backward(test_data, h, recon)\n",
    "print(f\"âœ… Complete autoencoder backward pass successful!\")\n",
    "print(f\"   All gradient shapes correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 8: Train Autoencoder and Analyze Results (10 minutes)\n",
    "\n",
    "Now let's train the autoencoder and visualize the reconstruction quality.\n",
    "\n",
    "**Your Task**: Set up training and analyze the learned representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time series data for training\n",
    "print(\"ðŸ“Š Preparing time series data...\")\n",
    "\n",
    "# TODO: Split time series data\n",
    "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(\n",
    "    ___,  # FILL: X_ts\n",
    "    ___,  # FILL: y_ts\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# TODO: Normalize sequences (important for training stability)\n",
    "# Normalize to zero mean and unit variance per sequence\n",
    "X_train_norm = (X_train_ts - X_train_ts.mean(axis=1, keepdims=True)) / (X_train_ts.std(axis=1, keepdims=True) + 1e-6)\n",
    "X_test_norm = (X_test_ts - X_test_ts.mean(axis=1, keepdims=True)) / (X_test_ts.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "print(f\"ðŸ“Š Training set: {X_train_norm.shape}\")\n",
    "print(f\"ðŸ“Š Test set: {X_test_norm.shape}\")\n",
    "print(f\"ðŸ“Š Normalized data range: [{X_train_norm.min():.2f}, {X_train_norm.max():.2f}]\")\n",
    "\n",
    "# TODO: Create and configure autoencoder\n",
    "# Hint: input_dim=sequence_length, hidden_dim=16 for compression\n",
    "ae = AutoencoderComplete(\n",
    "    input_dim=___,  # FILL: X_train_norm.shape[1]\n",
    "    hidden_dim=___,  # FILL: 16\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "print(f\"ðŸ§  Autoencoder: {ae.input_dim} â†’ {ae.hidden_dim} â†’ {ae.input_dim}\")\n",
    "print(f\"ðŸ“‰ Compression ratio: {ae.input_dim/ae.hidden_dim:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution and training\n",
    "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(\n",
    "    X_ts, y_ts, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "X_train_norm = (X_train_ts - X_train_ts.mean(axis=1, keepdims=True)) / (X_train_ts.std(axis=1, keepdims=True) + 1e-6)\n",
    "X_test_norm = (X_test_ts - X_test_ts.mean(axis=1, keepdims=True)) / (X_test_ts.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "ae = AutoencoderComplete(input_dim=X_train_norm.shape[1], hidden_dim=16, learning_rate=0.05)\n",
    "\n",
    "print(\"ðŸš€ Training autoencoder...\")\n",
    "ae_losses = ae.train(X_train_norm, epochs=30, batch_size=128, verbose=True)\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(ae_losses, 'b-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log scale to see improvement clearly\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“Š Training completed!\")\n",
    "print(f\"   Initial loss: {ae_losses[0]:.6f}\")\n",
    "print(f\"   Final loss: {ae_losses[-1]:.6f}\")\n",
    "print(f\"   Improvement: {(ae_losses[0] - ae_losses[-1])/ae_losses[0]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ” Visualize Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reconstruction quality\n",
    "print(\"ðŸ” Analyzing reconstruction quality...\")\n",
    "\n",
    "# Select examples from test set\n",
    "n_examples = 6\n",
    "example_indices = np.random.choice(len(X_test_norm), n_examples, replace=False)\n",
    "\n",
    "# Get reconstructions\n",
    "test_samples = X_test_norm[example_indices]\n",
    "reconstructions = ae.reconstruct(test_samples)\n",
    "\n",
    "# Plot original vs reconstructed\n",
    "fig, axes = plt.subplots(n_examples, 2, figsize=(12, 2*n_examples))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    idx = example_indices[i]\n",
    "    original = test_samples[i]\n",
    "    reconstructed = reconstructions[i]\n",
    "    \n",
    "    # Original sequence\n",
    "    axes[i, 0].plot(original, 'b-', linewidth=2, label='Original')\n",
    "    axes[i, 0].plot(reconstructed, 'r--', linewidth=2, label='Reconstructed')\n",
    "    axes[i, 0].set_ylabel(f\"Seq {idx}\\n(Class {y_test_ts[idx]})\")\n",
    "    axes[i, 0].legend()\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Reconstruction error\n",
    "    error = original - reconstructed\n",
    "    mse = np.mean(error**2)\n",
    "    axes[i, 1].plot(error, 'g-', linewidth=2)\n",
    "    axes[i, 1].set_ylabel(f\"Error\\n(MSE: {mse:.4f})\")\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 0].set_title(\"Original vs Reconstructed\")\n",
    "axes[0, 1].set_title(\"Reconstruction Error\")\n",
    "axes[-1, 0].set_xlabel(\"Time Step\")\n",
    "axes[-1, 1].set_xlabel(\"Time Step\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall reconstruction statistics\n",
    "all_reconstructions = ae.reconstruct(X_test_norm)\n",
    "mse_per_sample = np.mean((X_test_norm - all_reconstructions)**2, axis=1)\n",
    "print(f\"ðŸ“Š Reconstruction Quality Statistics:\")\n",
    "print(f\"   Mean MSE: {mse_per_sample.mean():.6f}\")\n",
    "print(f\"   Std MSE: {mse_per_sample.std():.6f}\")\n",
    "print(f\"   Best reconstruction MSE: {mse_per_sample.min():.6f}\")\n",
    "print(f\"   Worst reconstruction MSE: {mse_per_sample.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 9: Transfer Learning with Embeddings (10 minutes)\n",
    "\n",
    "Now let's use the learned representations for frequency classification.\n",
    "\n",
    "**Your Task**: Compare classification performance using autoencoder embeddings vs raw sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Extracting embeddings for classification...\")\n",
    "\n",
    "# TODO: Extract embeddings using the encoder\n",
    "train_embeddings = ___  # FILL: ae.encode(X_train_norm)\n",
    "test_embeddings = ___  # FILL: ae.encode(X_test_norm)\n",
    "\n",
    "print(f\"ðŸ“Š Embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"ðŸ“‰ Dimensionality reduction: {X_train_norm.shape[1]} â†’ {train_embeddings.shape[1]}\")\n",
    "\n",
    "# TODO: Train classifier on embeddings\n",
    "print(\"\\nðŸš€ Training classifiers...\")\n",
    "clf_embeddings = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_embeddings.fit(___) # FILL: train_embeddings, y_train_ts\n",
    "emb_acc = clf_embeddings.score(___) # FILL: test_embeddings, y_test_ts\n",
    "\n",
    "# TODO: Train baseline classifier on raw normalized sequences\n",
    "clf_raw_ts = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_raw_ts.fit(___) # FILL: X_train_norm, y_train_ts\n",
    "raw_acc = clf_raw_ts.score(___) # FILL: X_test_norm, y_test_ts\n",
    "\n",
    "print(f\"\\nðŸ“Š Time Series Classification Results:\")\n",
    "print(f\"   ðŸ§  Autoencoder Embeddings: {emb_acc:.3f}\")\n",
    "print(f\"   ðŸ“ˆ Raw Sequences: {raw_acc:.3f}\")\n",
    "print(f\"   ðŸ“Š Difference: {(emb_acc - raw_acc)*100:+.1f} percentage points\")\n",
    "\n",
    "if emb_acc >= raw_acc - 0.02:  # Within 2 percentage points\n",
    "    print(f\"   âœ… Embeddings retain discriminative information despite compression!\")\nelse:\n",
    "    print(f\"   âš ï¸ Some discriminative information lost in compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "train_embeddings = ae.encode(X_train_norm)\n",
    "test_embeddings = ae.encode(X_test_norm)\n",
    "\n",
    "clf_embeddings = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_embeddings.fit(train_embeddings, y_train_ts)\n",
    "emb_acc = clf_embeddings.score(test_embeddings, y_test_ts)\n",
    "\n",
    "clf_raw_ts = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf_raw_ts.fit(X_train_norm, y_train_ts)\n",
    "raw_acc = clf_raw_ts.score(X_test_norm, y_test_ts)\n",
    "\n",
    "print(f\"ðŸ“Š Time Series Classification Results:\")\n",
    "print(f\"   ðŸ§  Autoencoder Embeddings: {emb_acc:.3f}\")\n",
    "print(f\"   ðŸ“ˆ Raw Sequences: {raw_acc:.3f}\")\n",
    "print(f\"   ðŸ”¥ Compression: {X_train_norm.shape[1]} â†’ {train_embeddings.shape[1]} dimensions\")\n",
    "\n",
    "# Visualize embeddings with t-SNE\n",
    "print(\"\\nðŸŽ¨ Visualizing embedding space...\")\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(test_embeddings[:300])  # Subset for speed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'red']\n",
    "labels = ['Low Freq (1.0)', 'High Freq (3.0)']\n",
    "\n",
    "for class_id in [0, 1]:\n",
    "    mask = y_test_ts[:300] == class_id\n",
    "    plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "               c=colors[class_id], alpha=0.6, s=30, label=labels[class_id])\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('Autoencoder Embeddings Visualization (t-SNE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "if emb_acc >= raw_acc - 0.02:\n",
    "    print(\"âœ… Autoencoder successfully learned discriminative features!\")\n",
    "else:\n",
    "    print(\"ðŸ“ Note: Perfect separation isn't always expected - depends on noise level and frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Multiple Choice Question 2\n",
    "**What is the main benefit of using an autoencoder for self-supervised learning?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq2 = MultipleChoiceQuestion(\n",
    "    \"What is the main benefit of using an autoencoder for self-supervised learning?\",\n",
    "    [\n",
    "        \"It always produces better accuracy than supervised learning\",\n",
    "        \"It compresses data into a lower-dimensional representation while preserving important features\",\n",
    "        \"It can only work with time series data\",\n",
    "        \"It requires less computation than other SSL methods\"\n",
    "    ],\n",
    "    2,\n",
    "    \"The autoencoder's bottleneck architecture forces it to learn compressed representations that capture the most important aspects of the data, making it useful for dimensionality reduction and feature learning.\"\n",
    ")\n",
    "\n",
    "mcq2.display()\n",
    "# mcq2.check_answer(2)  # Replace with your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Advanced Concepts & Extensions (15 minutes)\n",
    "\n",
    "Let's explore more advanced SSL concepts and give you a chance to be creative!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Critical Thinking Question 3\n",
    "\n",
    "**We've seen two SSL approaches: rotation prediction (discriminative) and autoencoders (generative). What are the trade-offs between these approaches? When would you choose one over the other?**\n",
    "\n",
    "*Think about: computational efficiency, data requirements, robustness, and the types of features learned.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Exercise 10: Design a Novel Pretext Task (Creative Challenge)\n",
    "\n",
    "Now it's your turn to be creative! Design a novel pretext task for a domain of your choice.\n",
    "\n",
    "**Your Task**: Choose a data type and design a self-supervised pretext task. Implement a basic version if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for your creative pretext task\n",
    "\n",
    "print(\"ðŸŽ¨ Creative Exercise: Design Your Own Pretext Task\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nðŸ’¡ Instructions:\")\n",
    "print(\"1. Choose a data domain (text, audio, images, graphs, etc.)\")\n",
    "print(\"2. Design a pretext task where labels are automatically generated\")\n",
    "print(\"3. Explain why this task would learn useful features\")\n",
    "print(\"4. [Optional] Implement a basic version\")\n",
    "print(\"\\nðŸŒŸ Example ideas:\")\n",
    "print(\"   â€¢ Text: Predict if two sentences are consecutive in a document\")\n",
    "print(\"   â€¢ Audio: Predict the temporal order of audio segments\")\n",
    "print(\"   â€¢ Images: Predict relative spatial positions of image patches\")\n",
    "print(\"   â€¢ Graphs: Predict if two nodes are connected\")\n",
    "print(\"   â€¢ Video: Predict the speed of video playback\")\n",
    "\n",
    "# TODO: Describe your pretext task here\n",
    "your_pretext_task = \"\"\"\n",
    "TODO: Fill in your creative pretext task design\n",
    "\n",
    "Data Domain: [e.g., text, images, audio, etc.]\n",
    "\n",
    "Pretext Task: [Describe what the model needs to predict]\n",
    "\n",
    "Label Generation: [How are labels created automatically?]\n",
    "\n",
    "Why It Works: [What useful features would this task learn?]\n",
    "\n",
    "Potential Applications: [What downstream tasks could benefit?]\n",
    "\n",
    "Implementation Challenges: [What would be tricky to implement?]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nðŸ“ Your Pretext Task Design:\")\n",
    "print(your_pretext_task)\n",
    "\n",
    "# TODO: [Optional] Implement a basic version of your pretext task\n",
    "def your_pretext_task_implementation():\n",
    "    \"\"\"\n",
    "    Optional: Implement a basic version of your pretext task.\n",
    "    This could be data generation, a simple model, or just pseudocode.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "print(\"\\nðŸ’­ Reflection Questions:\")\n",
    "print(\"   â€¢ Is your task discriminative or generative?\")\n",
    "print(\"   â€¢ How difficult would it be to implement at scale?\")\n",
    "print(\"   â€¢ What domains could this transfer to?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Advanced SSL Concepts (Summary)\n",
    "\n",
    "Here are some cutting-edge SSL approaches you might explore further:\n",
    "\n",
    "### ðŸ”„ Contrastive Learning\n",
    "- **SimCLR**: Learn representations by maximizing agreement between different augmentations\n",
    "- **MoCo**: Maintain a momentum-updated queue of negative examples\n",
    "- **SwAV**: Use clustering assignments as pseudo-labels\n",
    "\n",
    "### ðŸŽ­ Masked Modeling\n",
    "- **BERT**: Mask words in sentences and predict them\n",
    "- **MAE**: Mask image patches and reconstruct them\n",
    "- **GraphMAE**: Mask nodes/edges in graphs\n",
    "\n",
    "### ðŸ”€ Multi-Modal SSL\n",
    "- **CLIP**: Learn joint text-image representations\n",
    "- **ALIGN**: Scale up text-image learning with noisy data\n",
    "- **AudioCLIP**: Extend to audio-visual learning\n",
    "\n",
    "### ðŸŽ¯ Domain-Specific SSL\n",
    "- **Protein folding**: Predict 3D structure from sequence\n",
    "- **Medical imaging**: Anatomical consistency checks\n",
    "- **Robotics**: Predict future states from actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Assessment & Reflection (15 minutes)\n",
    "\n",
    "Time to test your understanding with AI-powered evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– AI-Powered Open-Ended Assessment\n",
    "\n",
    "These questions will be evaluated automatically using Claude API if you have it configured.\n",
    "\n",
    "### Setting up Assessment\n",
    "Make sure you have `MY_APP_ANTHROPIC_KEY` set in your environment for automatic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessment system setup (same as before)\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "\n",
    "class OpenEndedAssessment:\n",
    "    \"\"\"Handle open-ended questions with Claude AI verification.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        self.api_key = api_key or os.getenv('MY_APP_ANTHROPIC_KEY')\n",
    "        self.questions = self._load_questions()\n",
    "        \n",
    "        if self.api_key:\n",
    "            try:\n",
    "                import anthropic\n",
    "                self.client = anthropic.Anthropic(api_key=self.api_key)\n",
    "                print(\"âœ… Claude API configured for automatic evaluation\")\n",
    "            except ImportError:\n",
    "                print(\"âš ï¸ Please install anthropic: pip install anthropic\")\n",
    "                self.client = None\n",
    "        else:\n",
    "            self.client = None\n",
    "            print(\"â„¹ï¸ No API key found - will use manual evaluation mode\")\n",
    "    \n",
    "    def _load_questions(self) -> List[Dict]:\n",
    "        return [\n",
    "            {\n",
    "                \"id\": \"q1\",\n",
    "                \"question\": \"Explain why rotation prediction is an effective pretext task for learning visual features. What properties of the task make it useful for downstream computer vision tasks?\",\n",
    "                \"rubric\": [\n",
    "                    \"Explains that rotation requires understanding geometric and spatial structure\",\n",
    "                    \"Notes that labels are automatically generated (no human annotation needed)\", \n",
    "                    \"Discusses how it forces learning of rotation-equivariant or invariant features\",\n",
    "                    \"Connects to usefulness for downstream tasks requiring spatial understanding\"\n",
    "                ],\n",
    "                \"sample_answer\": \"Rotation prediction is effective because it forces networks to understand spatial relationships and geometric structure in images. The task requires recognizing objects regardless of orientation, leading to rotation-equivariant representations. Labels are free since we can rotate any image and know the rotation angle. The learned features capture shape, structure, and spatial patterns that transfer well to classification, detection, and other vision tasks.\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"q2\", \n",
    "                \"question\": \"Compare and contrast autoencoders with contrastive learning methods for self-supervised learning. What are the strengths and weaknesses of each approach?\",\n",
    "                \"rubric\": [\n",
    "                    \"Identifies autoencoders as generative/reconstructive approach\",\n",
    "                    \"Identifies contrastive learning as discriminative approach\", \n",
    "                    \"Discusses computational and data efficiency differences\",\n",
    "                    \"Explains when to choose one approach over the other\"\n",
    "                ],\n",
    "                \"sample_answer\": \"Autoencoders learn by reconstructing inputs, capturing detailed information but potentially including noise. They're computationally simpler and work well for dimensionality reduction. Contrastive methods learn by comparing examples, focusing on discriminative features while ignoring irrelevant details. Contrastive approaches are more robust to noise and often learn better features for classification, but require careful augmentation strategies and can be computationally expensive. Choose autoencoders for compression and reconstruction tasks, contrastive methods for discriminative downstream tasks.\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"q3\",\n",
    "                \"question\": \"Design a novel self-supervised pretext task for a domain of your choice (not vision or time series). Explain your reasoning and why it would learn useful features.\",\n",
    "                \"rubric\": [\n",
    "                    \"Proposes a specific, well-defined pretext task for a clear domain\",\n",
    "                    \"Explains how supervision signals would be generated automatically\", \n",
    "                    \"Provides clear reasoning for why the task would learn useful features\",\n",
    "                    \"Discusses potential applications and transfer learning scenarios\"\n",
    "                ],\n",
    "                \"sample_answer\": \"For natural language processing, I propose 'discourse coherence prediction': given two paragraphs, predict whether they appear consecutively in the same document. This requires understanding topic flow, argument structure, and linguistic coherence markers. Labels are free since any document provides positive examples (consecutive paragraphs) and negative examples (random pairs). The model would learn discourse-level features useful for document classification, summarization, and text generation tasks.\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def evaluate_answer(self, question_id: str, user_answer: str) -> Dict:\n",
    "        question_data = next((q for q in self.questions if q['id'] == question_id), None)\n",
    "        if not question_data:\n",
    "            return {\"error\": \"Question not found\"}\n",
    "        \n",
    "        if not self.client:\n",
    "            return self._manual_evaluation(question_data, user_answer)\n",
    "        \n",
    "        try:\n",
    "            evaluation_prompt = self._create_evaluation_prompt(question_data, user_answer)\n",
    "            response = self._call_claude_api(evaluation_prompt)\n",
    "            return self._parse_evaluation(response)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"API call failed: {str(e)}\"}\n",
    "    \n",
    "    def _create_evaluation_prompt(self, question_data: Dict, user_answer: str) -> str:\n",
    "        prompt = f\"\"\"You are evaluating a student's understanding of self-supervised learning.\n",
    "\n",
    "Question: {question_data['question']}\n",
    "\n",
    "Evaluation Rubric (25 points each):\n",
    "{chr(10).join(f'- {item}' for item in question_data['rubric'])}\n",
    "\n",
    "Reference Answer: {question_data['sample_answer']}\n",
    "\n",
    "Student Answer: {user_answer}\n",
    "\n",
    "Please evaluate and provide a JSON response:\n",
    "{{\n",
    "    \"score\": <0-100>,\n",
    "    \"rubric_met\": [<addressed rubric points>],\n",
    "    \"strengths\": \"<what was done well>\",\n",
    "    \"improvements\": \"<areas for improvement>\",\n",
    "    \"feedback\": \"<encouraging constructive feedback>\"\n",
    "}}\n",
    "\n",
    "Be encouraging while providing honest evaluation. Focus on conceptual understanding.\n",
    "Return ONLY the JSON object.\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _call_claude_api(self, prompt: str) -> str:\n",
    "        message = self.client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=500,\n",
    "            temperature=0.3,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def _parse_evaluation(self, response: str) -> Dict:\n",
    "        try:\n",
    "            import re\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Failed to parse response\", \"raw_response\": response}\n",
    "    \n",
    "    def _manual_evaluation(self, question_data: Dict, user_answer: str) -> Dict:\n",
    "        return {\n",
    "            \"message\": \"Manual evaluation mode - use the rubric below to self-assess\",\n",
    "            \"rubric\": question_data['rubric'], \n",
    "            \"sample_answer\": question_data['sample_answer'],\n",
    "            \"your_answer\": user_answer,\n",
    "            \"instructions\": \"Compare your answer to the sample and rubric. Award yourself points for each addressed rubric item.\"\n",
    "        }\n",
    "\n",
    "def submit_answer(question_id: str, answer: str):\n",
    "    print(f\"\\nðŸ“Š Evaluating Question {question_id}...\\n\")\n",
    "    result = assessment.evaluate_answer(question_id, answer)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"âŒ Error: {result['error']}\")\n",
    "    elif 'message' in result:\n",
    "        print(f\"â„¹ï¸ {result['message']}\\n\")\n",
    "        print(\"ðŸ“‹ Rubric (25 points each):\")\n",
    "        for i, item in enumerate(result['rubric'], 1):\n",
    "            print(f\"  {i}. {item}\")\n",
    "        print(f\"\\nðŸ“– Sample Answer: {result['sample_answer']}\")\n",
    "        print(f\"\\nâœï¸ Your Answer: {result['your_answer']}\")\n",
    "    else:\n",
    "        print(f\"ðŸŽ¯ Score: {result['score']}/100\\n\")\n",
    "        if 'rubric_met' in result:\n",
    "            print(\"âœ… Rubric Points Addressed:\")\n",
    "            for point in result['rubric_met']:\n",
    "                print(f\"  â€¢ {point}\")\n",
    "        print(f\"\\nðŸ’ª Strengths: {result.get('strengths', 'N/A')}\")\n",
    "        print(f\"\\nðŸ“ˆ Areas for Improvement: {result.get('improvements', 'N/A')}\")\n",
    "        print(f\"\\nðŸ’¬ Feedback: {result.get('feedback', 'N/A')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Initialize assessment\n",
    "assessment = OpenEndedAssessment()\n",
    "print(\"\\nðŸ“ Assessment system ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Question 1: Rotation Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â“ Question 1: Rotation Prediction Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Explain why rotation prediction is an effective pretext task for learning visual features.\")\n",
    "print(\"What properties of the task make it useful for downstream computer vision tasks?\")\n",
    "print(\"\\nðŸ’¡ Think about: geometric understanding, label generation, learned features, transfer learning\")\n",
    "\n",
    "# TODO: Write your answer here\n",
    "my_answer_q1 = \"\"\"\n",
    "Write your thoughtful answer here...\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Uncomment to submit your answer\n",
    "# result_q1 = submit_answer(\"q1\", my_answer_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Question 2: Autoencoders vs Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â“ Question 2: Method Comparison\")\n",
    "print(\"=\" * 50) \n",
    "print(\"Compare and contrast autoencoders with contrastive learning methods.\")\n",
    "print(\"What are the strengths and weaknesses of each approach?\")\n",
    "print(\"\\nðŸ’¡ Think about: learning objectives, computational costs, robustness, use cases\")\n",
    "\n",
    "# TODO: Write your answer here\n",
    "my_answer_q2 = \"\"\"\n",
    "Write your comparative analysis here...\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Uncomment to submit your answer  \n",
    "# result_q2 = submit_answer(\"q2\", my_answer_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Question 3: Creative Pretext Task Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â“ Question 3: Creative Design Challenge\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Design a novel self-supervised pretext task for a domain of your choice.\")\n",
    "print(\"(Choose a domain other than computer vision or time series)\")\n",
    "print(\"\\nðŸ’¡ Consider: text, audio, graphs, biology, chemistry, social networks, etc.\")\n",
    "print(\"\\nðŸ“‹ Address: domain choice, task description, label generation, why it works, applications\")\n",
    "\n",
    "# TODO: Write your creative pretext task\n",
    "my_answer_q3 = \"\"\"\n",
    "Design your novel pretext task here...\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Uncomment to submit your answer\n",
    "# result_q3 = submit_answer(\"q3\", my_answer_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ‰ Congratulations! Lab Complete!\n",
    "\n",
    "## ðŸ“š What You've Accomplished\n",
    "\n",
    "âœ… **Understood SSL Fundamentals**: Learned the difference between generative and discriminative approaches\n",
    "\n",
    "âœ… **Implemented Rotation Prediction**: Built a complete SSL system from data generation to transfer learning\n",
    "\n",
    "âœ… **Built Neural Networks from Scratch**: Implemented forward/backward propagation using only NumPy\n",
    "\n",
    "âœ… **Created Autoencoders**: Developed generative SSL for time series reconstruction\n",
    "\n",
    "âœ… **Applied Transfer Learning**: Used SSL features for downstream classification tasks\n",
    "\n",
    "âœ… **Analyzed Representations**: Visualized learned features and embedding spaces\n",
    "\n",
    "âœ… **Designed Novel Tasks**: Created your own pretext task for a new domain\n",
    "\n",
    "## ðŸ§  Key Insights\n",
    "\n",
    "- **SSL generates its own supervision** from data structure\n",
    "- **Pretext tasks must be challenging enough** to force meaningful feature learning\n",
    "- **Transfer learning reveals representation quality** through downstream performance\n",
    "- **Different SSL approaches** (generative vs discriminative) have different strengths\n",
    "- **Domain knowledge is crucial** for designing effective pretext tasks\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "### ðŸ“– **Continue Learning**\n",
    "- Explore modern SSL methods: SimCLR, MoCo, MAE\n",
    "- Study domain-specific SSL applications\n",
    "- Learn about multi-modal SSL (CLIP, ALIGN)\n",
    "\n",
    "### ðŸ’» **Hands-On Projects**  \n",
    "- Implement SSL on your own datasets\n",
    "- Try SSL with real-world computer vision tasks\n",
    "- Experiment with different pretext tasks\n",
    "- Build SSL systems for text or audio\n",
    "\n",
    "### ðŸ”¬ **Research Directions**\n",
    "- Design pretext tasks for your domain\n",
    "- Investigate why SSL works theoretically\n",
    "- Combine multiple pretext tasks\n",
    "- Explore SSL for few-shot learning\n",
    "\n",
    "## ðŸŒŸ Final Reflection\n",
    "\n",
    "Self-supervised learning represents a paradigm shift in machine learning - leveraging the vast amounts of unlabeled data around us by finding clever ways to create supervision signals. The techniques you've learned here are actively used in cutting-edge AI systems, from language models to computer vision applications.\n",
    "\n",
    "The key to successful SSL is creativity: finding the right pretext task that forces models to learn the features you care about for downstream tasks. Keep experimenting, and remember that some of the best SSL ideas come from deep understanding of the data and domain!\n",
    "\n",
    "**Happy learning! ðŸŽ“**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python", 
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}